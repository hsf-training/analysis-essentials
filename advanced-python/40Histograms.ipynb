{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 6: Histograms\n",
    "\n",
    "In nearly every High Energy Physics analysis, histograms have their place:\n",
    "- plotting of variables\n",
    "- calculating efficiency correction tables (weights)\n",
    "- performing binned fits\n",
    "\n",
    "and many more.\n",
    "\n",
    "Scikit-HEP offers libraries to deal with histograms in Python in a performant way:\n",
    "[hist](https://hist.readthedocs.io/en/latest/) is a user-friendly analysis library for histograms\n",
    "and is directly built on top of the workhorse [boost-histogram](https://boost-histogram.readthedocs.io/en/latest/),\n",
    "which can also be used directly. Hist simply provides more functionality.\n",
    "\n",
    "They are written by the same authors and can also be used often together.\n",
    "\n",
    "Both also work well together with mplhep, the plotting library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-11-09T18:40:45.090763040Z",
     "start_time": "2023-11-09T18:40:41.774097506Z"
    }
   },
   "outputs": [],
   "source": [
    "# jupyter magic to load the previous data sets\n",
    "%store -r bkg_df\n",
    "%store -r mc_df\n",
    "%store -r data_df\n",
    "\n",
    "import boost_histogram as bh\n",
    "import hist\n",
    "import mplhep\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-11-09T18:40:45.092581529Z",
     "start_time": "2023-11-09T18:40:42.719110990Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's get started with a simple example\n",
    "\n",
    "# Compose axis however you like; this is a 2D histogram\n",
    "h = bh.Histogram(bh.axis.Regular(2, 0, 1),\n",
    "                 bh.axis.Regular(4, 0.0, 1.0))\n",
    "\n",
    "# Filling can be done with arrays, one per dimension\n",
    "h.fill([.3, .5, .2],\n",
    "          [.1, .4, .9])\n",
    "\n",
    "# NumPy array view into histogram counts, no overflow bins\n",
    "counts = h.view()\n",
    "variances = h.variances()\n",
    "mplhep.hist2dplot(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Axes\n",
    "\n",
    "A cental part of a histogram are the axes: They difine the binning and other treats of the axis.\n",
    "\n",
    "A Hist (*this refers by default to hist.Hist, but usually also applies for bh.Histogram as the former inherits\n",
    "from the latter*) can have multiple axes of different types.\n",
    "\n",
    "All axes are described [here](https://hist.readthedocs.io/en/latest/user-guide/axes.html#axes).\n",
    "\n",
    "\n",
    "\n",
    "The most important types are\n",
    "\n",
    "\n",
    "### Regular\n",
    "\n",
    "This is an axis with lower, upper limits, **regularly** split into n bins.\n",
    "\n",
    "```\n",
    "axis_reg = hist.axis.Regular(nbins, lower, upper, name=name)\n",
    "```\n",
    "\n",
    "### Variable\n",
    "\n",
    "A variable axis allows to set the bin edges arbitrarily using an array-like object.mro\n",
    "```\n",
    "axis_var = hist.axis.Variable([0, 0.5, 3.1, 3.4], name=\"eta\")\n",
    "```\n",
    "\n",
    "## Axis Name\n",
    "\n",
    "An axis (in hist, in bh only a label is possible) have a name, which can be used as the identifier\n",
    "when working with the histogram (instead of using plain integer indexes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T18:40:45.092804229Z",
     "start_time": "2023-11-09T18:40:42.910621980Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T18:40:45.092969634Z",
     "start_time": "2023-11-09T18:40:42.916739161Z"
    }
   },
   "outputs": [],
   "source": [
    "start, stop = data_df['Jpsi_M'].min(), data_df['Jpsi_M'].max()\n",
    "axis1 = hist.axis.Regular(bins=50, start=start, stop=stop, name=\"mass\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a histogram, we can pass one or multiple axes to a histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-11-09T18:40:45.093124685Z",
     "start_time": "2023-11-09T18:40:42.927046922Z"
    }
   },
   "outputs": [],
   "source": [
    "data_h = hist.Hist(axis1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T18:40:45.094256975Z",
     "start_time": "2023-11-09T18:40:42.937126378Z"
    }
   },
   "outputs": [],
   "source": [
    "data_h.fill(data_df['Jpsi_M'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T18:40:45.094471841Z",
     "start_time": "2023-11-09T18:40:42.949363041Z"
    }
   },
   "outputs": [],
   "source": [
    "mc_h = hist.Hist(axis1).fill(mc_df['Jpsi_M'])  # we can also chain the commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compatibility with mplhep\n",
    "\n",
    "With bh and hist, the [Unified Histogram Interface](https://github.com/scikit-hep/uhi) was also born. This allows objects to be plotted so that a library such as mplhep knows what to do with it.\n",
    "\n",
    "In short, mplhep and hist work seemless together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T18:40:45.095025556Z",
     "start_time": "2023-11-09T18:40:42.955171365Z"
    }
   },
   "outputs": [],
   "source": [
    "mplhep.histplot(data_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting with hist\n",
    "\n",
    "\n",
    "hist itself provides also plotting functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T18:40:45.095656170Z",
     "start_time": "2023-11-09T18:40:43.211187900Z"
    }
   },
   "outputs": [],
   "source": [
    "data_h.plot1d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T18:40:45.096292049Z",
     "start_time": "2023-11-09T18:40:43.415174250Z"
    }
   },
   "outputs": [],
   "source": [
    "data_h.plot1d()\n",
    "mc_h.plot1d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T18:40:45.096697901Z",
     "start_time": "2023-11-09T18:40:43.622364563Z"
    }
   },
   "outputs": [],
   "source": [
    "mc_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple dimensions\n",
    "\n",
    "Histograms can be multiple dimensional. Let's add a dimension to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T18:40:45.097017931Z",
     "start_time": "2023-11-09T18:40:43.629433139Z"
    }
   },
   "outputs": [],
   "source": [
    "start, stop = data_df['BDT'].min(), data_df['BDT'].max()\n",
    "axis_bdt = hist.axis.Regular(bins=20, start=start, stop=stop, name=\"BDT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T18:40:45.097244707Z",
     "start_time": "2023-11-09T18:40:43.671235206Z"
    }
   },
   "outputs": [],
   "source": [
    "mc_h2d = hist.Hist(axis1, axis_bdt).fill(BDT=mc_df['BDT'], mass=mc_df['Jpsi_M']) # using names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T18:40:45.136940250Z",
     "start_time": "2023-11-09T18:40:43.671469880Z"
    }
   },
   "outputs": [],
   "source": [
    "data_h2d = hist.Hist(axis1, axis_bdt)\n",
    "data_h2d.fill(data_df['Jpsi_M'], data_df['BDT']) # order based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T18:40:45.138342837Z",
     "start_time": "2023-11-09T18:40:43.712937233Z"
    }
   },
   "outputs": [],
   "source": [
    "mplhep.hist2dplot(data_h2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access Bins\n",
    "\n",
    "hist allows you to access the bins of your Hist by various ways. Besides the normal access by index, you can use locations (supported by boost-histogram), complex numbers, and the dictionary to access the bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T18:40:45.138747800Z",
     "start_time": "2023-11-09T18:40:44.022960001Z"
    }
   },
   "outputs": [],
   "source": [
    "# Access by bin number\n",
    "data_h2d[35, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Density\n",
    "\n",
    "If you want to get the density of an existing histogram, .density() is capable to do it and will return you the density array without overflow and underflow bins.\n",
    "\n",
    "A histogram is a count, so it's an **integral over a density**. To obtain the density, one can devide by the area of the bin, this gives the \"average density\" in a bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T18:40:45.140841528Z",
     "start_time": "2023-11-09T18:40:44.029760988Z"
    }
   },
   "outputs": [],
   "source": [
    "data_h2d.density()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projecting axes\n",
    "\n",
    "We can also project onto a certain axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T18:40:45.142148636Z",
     "start_time": "2023-11-09T18:40:44.062252938Z"
    }
   },
   "outputs": [],
   "source": [
    "data_h2d.project(\"mass\")  # we will here retain the 1D histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing everything relevant\n",
    "\n",
    "Hist is transparent and let's us use many things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T18:40:45.142629942Z",
     "start_time": "2023-11-09T18:40:44.071307572Z"
    }
   },
   "outputs": [],
   "source": [
    "data_h2d.axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T18:40:45.143016256Z",
     "start_time": "2023-11-09T18:40:44.076331708Z"
    }
   },
   "outputs": [],
   "source": [
    "data_h2d.axes['mass']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T18:40:45.143633118Z",
     "start_time": "2023-11-09T18:40:44.087011298Z"
    }
   },
   "outputs": [],
   "source": [
    "data_h2d.axes['mass'].edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T18:40:45.144130758Z",
     "start_time": "2023-11-09T18:40:44.098073547Z"
    }
   },
   "outputs": [],
   "source": [
    "data_h2d.axes['mass'].centers  # bin centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T18:40:45.144584441Z",
     "start_time": "2023-11-09T18:40:44.102908180Z"
    }
   },
   "outputs": [],
   "source": [
    "data_h2d.axes['mass'].widths  # bin widths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi dimensional\n",
    "\n",
    "All this attributes are also already available in `edges`, they are ready to be broadcasted. So they have the shape of (1, ..., N, ..., 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T18:40:45.145653144Z",
     "start_time": "2023-11-09T18:40:44.111345363Z"
    }
   },
   "outputs": [],
   "source": [
    "data_h2d.axes.edges\n",
    "data_h2d.axes['mass'].centers\n",
    "data_h2d.axes['mass'].widths\n",
    "areas = np.prod(data_h2d.axes.widths, axis=0)\n",
    "print(f\"areas = {areas}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: can you obtain the density?\n",
    "\n",
    "use `hist.values` or `hist.views()`  (the latter makes no copy, the former does)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T18:40:45.145851826Z",
     "start_time": "2023-11-09T18:40:44.159338713Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arithmetics\n",
    "\n",
    "We can use the histograms to do math! We can multiply, add with each other or with scalars.\n",
    "\n",
    "We can find the ratio between two histograms by dividing them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T18:40:45.172428378Z",
     "start_time": "2023-11-09T18:40:44.159650878Z"
    }
   },
   "outputs": [],
   "source": [
    "data_df_bdt = data_df.query(\"BDT > 0.9\")\n",
    "\n",
    "data_bdt_h2d = hist.Hist(axis1, axis_bdt)\n",
    "data_bdt_h2d.fill(data_df_bdt['Jpsi_M'], data_df_bdt['BDT']) # order based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T18:40:45.173168648Z",
     "start_time": "2023-11-09T18:40:44.190637837Z"
    }
   },
   "outputs": [],
   "source": [
    "ratio = data_bdt_h2d.project(\"mass\") / data_h2d.project(\"mass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T18:40:45.200611311Z",
     "start_time": "2023-11-09T18:40:44.231188307Z"
    }
   },
   "outputs": [],
   "source": [
    "ratio.plot1d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T18:40:45.213022780Z",
     "start_time": "2023-11-09T18:40:44.419136722Z"
    }
   },
   "outputs": [],
   "source": [
    "ratio_large = ratio * 10\n",
    "ratio_large.plot1d()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: use the subtraction to \"remove\" the signal from the data file using the BDT cut hist. This should be the same as using only \"BDT<0.9\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T18:40:45.213326313Z",
     "start_time": "2023-11-09T18:40:44.667191807Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weights\n",
    "\n",
    "Weights are an essential part in HEP histograms and hist fully supports weigths. We can simply give an array of weights when filling the histogram.\n",
    "\n",
    "We first need to specify the storage type to be of type `Weight` in order to make sure we keep track of the weigths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T18:40:45.213535481Z",
     "start_time": "2023-11-09T18:40:44.667447153Z"
    }
   },
   "outputs": [],
   "source": [
    "weight = np.random.normal(1., 0.1, size=mc_df.shape[0])\n",
    "storage = hist.storage.Weight()\n",
    "mc_h2d = hist.Hist(axis1, axis_bdt, storage=storage).fill(BDT=mc_df['BDT'], mass=mc_df['Jpsi_M'], weight=weight) # using names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T18:40:45.231990095Z",
     "start_time": "2023-11-09T18:40:44.667709042Z"
    }
   },
   "outputs": [],
   "source": [
    "mc_h2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T18:40:45.395015033Z",
     "start_time": "2023-11-09T18:40:44.698968002Z"
    }
   },
   "outputs": [],
   "source": [
    "mc_h2d.variances()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: implement a function that calculates a weighted chi2 using two histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T18:40:45.395215588Z",
     "start_time": "2023-11-09T18:40:44.743359631Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
