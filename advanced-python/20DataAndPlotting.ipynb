{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2: First look at data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson we will look at a toy dataset simulating $J/\\psi \\rightarrow \\mu^+ \\mu^-$ events. We will discuss ways of loading the data in python,\n",
    "data formats and plotting with ```matplotlib``` and [mplhep](https://mplhep.readthedocs.io/en/latest/index.html).\n",
    "\n",
    "### Two plotting libraries?\n",
    "While ```matplotlib``` is a general Python library, the latter is a [Scikit-HEP](https://scikit-hep.org/) package. Scikit-HEP is an organisation which collects, improves and maintains Python packages that are still general, yet\n",
    " cover (often rather special) use cases in High Energy Physics. ```mplhep``` as an example provides plotting functionality  and styles to mimic typical plots that you see in HEP. However, it's built completely\n",
    " on top of matplotlib and the same can be achieved with pure matplotlib (but more cumbersome). Another example is uproot that we will use to read ROOT files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recap: Importing modules\n",
    "\n",
    "It's generally seen as good practice to put imports at the top of your file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mplhep\n",
    "import numpy as np\n",
    "import uproot\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. The toy dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to look at some fake $J/\\psi \\rightarrow \\mu^+ \\mu^-$ data, the variables available are:\n",
    "\n",
    "- `Jpsi_M` `Jpsi_P` `Jpsi_PT` `Jpsi_PE` `Jpsi_PX` `Jpsi_PY` `Jpsi_PZ`\n",
    "- `mum_M` `mum_PT` `mum_eta` `mum_PE` `mum_PX` `mum_PY` `mum_PZ` `mum_IP` `mum_ProbNNmu` `mum_ProbNNpi`\n",
    "- `mup_M` `mup_PT` `mup_eta` `mup_PE` `mup_PX` `mup_PY` `mup_PZ` `mup_IP` `mup_ProbNNmu` `mup_ProbNNpi`\n",
    "- `nTracks`\n",
    "\n",
    "The meaning of the suffixes are as follows:\n",
    "\n",
    "- `_M`: Invariant mass of the particle (fixed to the PDG value for muons)\n",
    "- `_P`: Absolute value of the particle's three momentum\n",
    "- `_PT`: Absolute value of the particle's momentum in the `x`-`y` plane\n",
    "- `_PE`, `_PX`, `_PY`, `_PZ`: Four momentum component of the particle\n",
    "- `_IP`: Impact parameter, i.e. the distance of closest approach between the reconstructed particle and the primary vertex\n",
    "- `ProbNNmu`, `ProbNNpi`: Particle identification variables which correspond to how likely it is that the particle is a muon or a pion\n",
    "- `nTracks`: The total number of tracks in the event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data\n",
    "\n",
    " - `uproot` is a way of reading ROOT files without having ROOT installed, see the github reposity [here](https://github.com/scikit-hep/uproot)\n",
    " - We can look at the objects that are available in the file and access objects using dictionary style syntax\n",
    " - The tree class contains converters to a variety of common Python libraries, such as numpy\n",
    " - We will also use `pandas DataFrames` to load data in a table like format\n",
    " (- `root_numpy` and `root_pandas` are an alternative, yet outdated, way of reading+writing ROOT files)\n",
    "\n",
    "First let's load the data using `uproot`.\n",
    "\n",
    "Often it is convenient to access data stored on the *grid* at CERN, so you don't have to keep it locally. This can be done using the *XRootD* protocol:\n",
    "\n",
    "```python\n",
    "my_file = uproot.open('root://eosuser.cern.ch//eos/user/l/lhcbsk/advanced-python/data/real_data.root')\n",
    "```\n",
    "or even better\n",
    "\n",
    "```python\n",
    "with uproot.open('root://eosuser.cern.ch//eos/user/l/lhcbsk/advanced-python/data/real_data.root') as my_file:\n",
    "   ...  # do something here with my_file\n",
    "```\n",
    "\n",
    "Accessing data this way requires you to have valid CERN credentials to access it. If authentication fails you will see an error message like:\n",
    "\n",
    "```\n",
    "OSError: [ERROR] Server responded with an error: [3010] Unable to give access - user access restricted - unauthorized identity used ; Permission denied\n",
    "```\n",
    "\n",
    "Credentials can be obtained by typing `kinit username@CERN.CH` in your terminal and entering your CERN password.\n",
    "\n",
    "For this tutorial we will use a publicly accessible file instead, using HTTPS to access it remotely. This is significantly slower than using XRootD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_file = uproot.open('https://cern.ch/starterkit/data/advanced-python-2018/real_data.root')\n",
    "\n",
    "my_file.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get a single variable, we can use the indexing. The `array` convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = my_file['DecayTree']\n",
    "# Get a numpy array containing the J/Î¨ mass\n",
    "tree['Jpsi_M'].array(library='np')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data as a pandas DataFrame\n",
    "data_df = tree.arrays(library='pd')\n",
    "my_file.close()  # usually, it's better to open the file with a \"with\" statement -> needs no closing\n",
    "\n",
    "# Show the first 5 lines of the DataFrame\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Plotting a simple histogram\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with a basic histogram\n",
    "plt.hist(data_df['Jpsi_M'])\n",
    "plt.xlabel('Jpsi mass')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's okay but we could improve it.\n",
    "\n",
    "Matplotlib\n",
    " - https://matplotlib.org/api/_as_gen/matplotlib.pyplot.hist.html\n",
    " - Internally it calls `np.histogram` and  returns an array of counts, an array of bins (as `np.histogram` does) and an array of patches.\n",
    " - We can use `histtype=\"step\"` so we can plot multiple datasets on the same axis easily\n",
    "\n",
    "However, this leaves us with a few things:\n",
    " - what if we have our data already as a histogram?\n",
    " - We usually want to have uncertainties on the histogram\n",
    " - It should match rather the usual style of plots\n",
    "\n",
    "That's where ```mplhep``` comes into play!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# One of the features of mplhep is that we can set an experiment specific style\n",
    "\n",
    "plt.style.use(mplhep.style.LHCb2)  # or ATLAS/CMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# plotting again\n",
    "plt.hist(data_df['Jpsi_M'], bins=40)\n",
    "plt.xlabel('Jpsi mass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# And similar with mplhep\n",
    "mplhep.histplot(*np.histogram(data_df['Jpsi_M'], bins=30))\n",
    "plt.xlabel('Jpsi mass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ... except that it can do a lot more!\n",
    "\n",
    "# we need to histogram only once!\n",
    "h, bins = np.histogram(data_df['Jpsi_M'], bins=50)  # TRY OUT: change the binning\n",
    "plt.subplots(1,2,figsize=(20, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "mplhep.histplot(h, bins, yerr=True)  # error can also be array\n",
    "plt.subplot(1, 2, 2)\n",
    "half_binwidths = (bins[1] - bins[0]) / 2\n",
    "mplhep.histplot(h, bins, histtype='errorbar', yerr=True, xerr=half_binwidths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mass(df):\n",
    "    h, bins = np.histogram(df['Jpsi_M'], bins=100, range=[2.75, 3.5])\n",
    "    mplhep.histplot(h, bins, yerr=True)  # feel free to adjust\n",
    "    # You can also use LaTeX in the axis label\n",
    "    plt.xlabel('$J/\\\\psi$ mass [GeV]')\n",
    "    plt.xlim(bins[0], bins[-1])\n",
    "\n",
    "\n",
    "plot_mass(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When making the ROOT file we forgot to add some variables, no bother lets add them now!\n",
    "data_df.eval('Jpsi_eta = arctanh(Jpsi_PZ/Jpsi_P)', inplace=True)\n",
    "data_df.head()['Jpsi_eta']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Add `mu_P` and `mum_P` columns to the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.eval('mup_P = sqrt(mup_PX**2 + mup_PY**2 + mup_PZ**2)', inplace=True)\n",
    "data_df.eval('mum_P = sqrt(mum_PX**2 + mum_PY**2 + mum_PZ**2)', inplace=True)\n",
    "# We can also get multiple columns at the same time\n",
    "data_df.head()[['mum_P', 'mup_P']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using rectangular cuts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We want to increase the 'signal significance' of our sample - this means more signal events with respect to background\n",
    "* To do this we can cut on certain discriminating variables\n",
    "* Here we will make cuts on the `Jpsi_PT` and **PID** (Particle Identification) variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mass(data_df)\n",
    "data_with_cuts_df = data_df.query('Jpsi_PT > 4')\n",
    "plot_mass(data_with_cuts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mass(data_df)\n",
    "data_with_cuts_df = data_df.query('Jpsi_PT > 4')\n",
    "plot_mass(data_with_cuts_df)\n",
    "# Lets add some PID cuts as well\n",
    "data_with_cuts_df = data_df.query('(Jpsi_PT > 4) & ((mum_ProbNNmu > 0.9) & (mup_ProbNNmu > 0.9))')\n",
    "plot_mass(data_with_cuts_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go back and add a label argument to our plot function. This makes it easier to identify each line.\n",
    "We can also use the `density` argument in `matplotlib.hist` to plot all the histograms as the same scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mass(df, **kwargs):\n",
    "    h, bins = np.histogram(df['Jpsi_M'], bins=100, range=[2.75, 3.5])\n",
    "    mplhep.histplot(h, bins, yerr=True, **kwargs)  # feel free to adjust\n",
    "    # You can also use LaTeX in the axis label\n",
    "    plt.xlabel('$J/\\\\psi$ mass [GeV]')\n",
    "    plt.xlim(bins[0], bins[-1])\n",
    "\n",
    "\n",
    "plot_mass(data_df, label='No cuts', density=1)\n",
    "data_with_cuts_df = data_df.query('Jpsi_PT > 4')\n",
    "plot_mass(data_with_cuts_df, label='$J/\\\\psi$ p$_T$ only', density=1)\n",
    "data_with_cuts_df = data_df.query('(Jpsi_PT > 4) & ((mum_ProbNNmu > 0.9) & (mup_ProbNNmu > 0.9))')\n",
    "plot_mass(data_with_cuts_df, label='$J/\\\\psi$ p$_T$ and muon PID', density=1)\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this tutorial we have a special function for testing the significance of the signal in our dataset. There are many ways to do this with real data, though we will not cover them here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_lesson import check_truth\n",
    "\n",
    "print('Originally the significance is')\n",
    "check_truth(data_df)\n",
    "\n",
    "print('\\nCutting on pT gives us')\n",
    "check_truth(data_df.query('Jpsi_PT > 4'))\n",
    "\n",
    "print('\\nCutting on pT and ProbNNmu gives us')\n",
    "check_truth(data_df.query('(Jpsi_PT > 4) & ((mum_ProbNNmu > 0.9) & (mup_ProbNNmu > 0.9))'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Comparing distributions\n",
    "\n",
    "Before we just used the cuts that were told to you but how do we pick them?\n",
    "\n",
    "One way is to get a sample of simulated data, we have a file in `data/simulated_data.root`.\n",
    "\n",
    "**Exercise:** Load it into a pandas `DataFrame` called `mc_df`. Don't forget to add the `Jpsi_eta`, `mup_P` and `mum_P` columns!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with uproot.open('https://starterkit.web.cern.ch/starterkit/data/advanced-python-2018/simulated_data.root') as mc_file:\n",
    "    mc_df = mc_file['DecayTree'].arrays(library='pd')\n",
    "\n",
    "# mc_file = uproot.open('https://starterkit.web.cern.ch/starterkit/data/advanced-python-2018/simulated_data.root')\n",
    "# mc_df = mc_file['DecayTree'].arrays(library='pd')\n",
    "mc_df.eval('Jpsi_eta = arctanh(Jpsi_PZ/Jpsi_P)', inplace=True)\n",
    "mc_df.eval('mup_P = sqrt(mum_PX**2 + mum_PY**2 + mum_PZ**2)', inplace=True)\n",
    "mc_df.eval('mum_P = sqrt(mum_PX**2 + mum_PY**2 + mum_PZ**2)', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION:** What can we to get a background sample?\n",
    "\n",
    "Sidebands, we know the peak is only present in $3.0~\\text{GeV} < M(J/\\psi) < 3.2~\\text{GeV}$. If we select events outside the region we know it's a pure background sample.\n",
    "\n",
    "**Exercise:** Make a new `DataFrame` called `bkg_df` containing only events outside $3.0~\\text{GeV} < M(J/\\psi) < 3.2~\\text{GeV}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bkg_df = data_df.query('~(3.0 < Jpsi_M < 3.2)')\n",
    "plot_mass(bkg_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION:** Why is there a step at 3 GeV on this plot?\n",
    "\n",
    "It's a binning effect, we've appled a cut at 3.0 GeV but the nearest bin is $[2.9975, 3.005]$ so it is only partially filled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot the variables in MC and background to see what they look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'Jpsi_PT'\n",
    "# let's first create the histograms\n",
    "hsig, bins = np.histogram(mc_df[var], bins=60)\n",
    "hbkg, bins = np.histogram(bkg_df[var], bins=bins)  # using the same bins here\n",
    "# then plot them\n",
    "mplhep.histplot((hsig, bins), label='MC Signal')\n",
    "mplhep.histplot(hbkg, bins=bins, label='Data Bkg')\n",
    "plt.xlabel(var)\n",
    "plt.xlim(bins[0], bins[-1])\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Those are hard to compare!\n",
    "# We can add the density keyword argument to normalise the distributions\n",
    "\n",
    "mplhep.histplot(hsig, bins=bins, label='MC Signal', density=1)\n",
    "mplhep.histplot(hbkg, bins=bins, label='Data Bkg', density=1)\n",
    "plt.xlabel(var)\n",
    "plt.xlim(bins[0], bins[-1])\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Make a function which plots both variables with the signature `plot_comparision(var, mc_df, bkg_df)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_comparision(var, mc_df, bkg_df):\n",
    "    # create histograms\n",
    "    hsig, bins = np.histogram(mc_df[var], bins=60, density=1)\n",
    "    hbkg, bins = np.histogram(bkg_df[var], bins=bins, density=1)\n",
    "\n",
    "    mplhep.histplot((hsig, bins), label='MC Signal', )\n",
    "    mplhep.histplot(hbkg, bins=bins, label='Data Bkg')\n",
    "    plt.xlabel(var)\n",
    "    plt.xlim(bins[0], bins[-1])\n",
    "    plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use this function to plot all of the variables available in the data using `data_df.columns`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in data_df.columns:\n",
    "    plt.figure()  # creates a new figure\n",
    "    plot_comparision(var, mc_df, bkg_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to note:\n",
    "\n",
    " - This doesn't work for the $J/\\psi$ mass variable: We can only rely on this method if the variable is independent of the mass. Fortunately we often want to do this as if a variable is heavily dependent on mass it can shape our distributions and can make it hard to know what is signal and what is background.\n",
    " - Muon mass is a fixed value for all muons: In this sample we have assumed the PDG value of the muon mass to allow us to calculate the energy component using only the information from the tracking detectors. This is often more precise than using calorimeters to measure $P_E$.\n",
    " - We got a warning about `More than 20 figures have been opened.`: Opening plots uses memory so if you open too many at the same time your scripts can be become slow or even crash. In this case we can ignore it as we only produce 30 plots but be careful if you ever make thousands of plots.\n",
    " - Pseudorapidity (eta) only goes between about 1 and 6: This dataset is supposed to look vaguely like LHCb data where the detector only covers that region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Look at the variables above and try to get a clean $J/\\psi$ mass peak. Use the significance function to see how well you do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aside:** We will want to use some of the variables and dataframes in the next lesson. In order to do this we will *store* them in this session and reload them in the next lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%store bkg_df\n",
    "%store mc_df\n",
    "%store data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
