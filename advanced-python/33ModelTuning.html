<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Model tuning setup &mdash; Analysis essentials  documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="../_static/panels.css?v=69fd799d" />
      <link rel="stylesheet" type="text/css" href="../_static/hsf.css?v=4f53b0d7" />
      <link rel="stylesheet" type="text/css" href="../_static/nbsphinx-code-cells.css" />

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../_static/jquery.js?v=5d32c60e"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../_static/documentation_options.js?v=5929fcd5"></script>
        <script src="../_static/doctools.js?v=888ff710"></script>
        <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
        <script data-domain="hepsoftwarefoundation.org" defer="defer" src="https://views.scientific-python.org/js/script.js"></script>
        <script src="../_static/panels.js?v=0f4bdeea"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="6: Histograms" href="40Histograms.html" />
    <link rel="prev" title="5: Boosting to Uniformity" href="32BoostingToUniformity.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            Analysis essentials
              <img src="../_static/hsf_logo_angled.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../python/README.html">An introduction to Python</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../python/running.html">Running Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="../python/00scripts.html">Scripting</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../python/00scripts.html#argparse">argparse</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../python/01basics.html">1: Basics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../python/01basics.html#Jupyter">Jupyter</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../python/01basics.html#Basic-types-and-operations">Basic types and operations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../python/01basics.html#strong-typing">strong typing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../python/01basics.html#Container-types">Container types</a></li>
<li class="toctree-l3"><a class="reference internal" href="../python/01basics.html#Mutability">Mutability</a></li>
<li class="toctree-l3"><a class="reference internal" href="../python/01basics.html#dynamic-typing">dynamic typing</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../python/01basics.html#Assignement-and-variables">Assignement and variables</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../python/01basics.html#Python-variable-assignement">Python variable assignement</a></li>
<li class="toctree-l3"><a class="reference internal" href="../python/01basics.html#Sugar:-comprehensions">Sugar: comprehensions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../python/01basics.html#Sugar:-using-Markdown">Sugar: using Markdown</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../python/operators.html">Objects and operators</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../python/operators.html#objects">Objects</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../python/numbers.html">Numbers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../python/strings.html">Strings</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../python/strings.html#formatting">Formatting</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../python/lists.html">Lists and looping</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../python/lists.html#looping">Looping</a></li>
<li class="toctree-l3"><a class="reference internal" href="../python/lists.html#list-comprehension">List comprehension</a></li>
<li class="toctree-l3"><a class="reference internal" href="../python/lists.html#tuples">Tuples</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../python/dictionaries.html">Dictionaries</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../python/dictionaries.html#dictionary-keys">Dictionary keys</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../python/conditions.html">Conditions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../python/conditions.html#truthiness">Truthiness</a></li>
<li class="toctree-l3"><a class="reference internal" href="../python/conditions.html#conditions-in-loops">Conditions in loops</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../python/methods.html">Functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../python/methods.html#inline-methods">Inline methods</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../python/scripting.html">Scripting</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../python/scripting.html#argparse">argparse</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../python/modules.html">Modules</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../python/modules.html#using-modules-into-your-code-import">Using modules into your code: import</a></li>
<li class="toctree-l3"><a class="reference internal" href="../python/modules.html#the-standard-library">The standard library</a></li>
<li class="toctree-l3"><a class="reference internal" href="../python/modules.html#modules-from-pypi">Modules from PyPi</a></li>
<li class="toctree-l3"><a class="reference internal" href="../python/modules.html#modules-inside-a-virtual-environment">Modules inside a virtual environment</a></li>
<li class="toctree-l3"><a class="reference internal" href="../python/modules.html#write-your-first-python-module">Write your first Python module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../python/modules.html#write-a-structured-module">Write a structured module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../python/modules.html#run-a-module">Run a module</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../python/classes.html">Classes</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../python/classes.html#Welcome-to-classes">Welcome to classes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../python/classes.html#Inheritance:-a-glance">Inheritance: a glance</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../python/classes.html#How-to-fix">How to fix</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../python/learning.html">Learning more</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../python/learning.html#exploring-python">Exploring Python</a></li>
<li class="toctree-l3"><a class="reference internal" href="../python/learning.html#conventional-coding">Conventional coding</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../python/first_histogram.html">Making your first histogram</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../python/first_histogram.html#pandas">Pandas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../python/first_histogram.html#plotting-histograms">Plotting histograms</a></li>
<li class="toctree-l3"><a class="reference internal" href="../python/first_histogram.html#applying-cuts">Applying cuts</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../python/further_reading.html">More advanced topics in Python</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../python/further_reading.html#nice-standard-libraries">Nice standard libraries</a></li>
<li class="toctree-l3"><a class="reference internal" href="../python/further_reading.html#nice-libraries-for-data-analysis">Nice libraries for data analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="../python/further_reading.html#python-and-root">Python and ROOT</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="README.html">Advanced Python Tutorial</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="10Basics.html">1: Basics</a><ul>
<li class="toctree-l3"><a class="reference internal" href="10Basics.html#Basics">Basics</a></li>
<li class="toctree-l3"><a class="reference internal" href="10Basics.html#Markdown">Markdown</a></li>
<li class="toctree-l3"><a class="reference internal" href="10Basics.html#Jupyter">Jupyter</a></li>
<li class="toctree-l3"><a class="reference internal" href="10Basics.html#Importing-modules">Importing modules</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="11AdvancedPython.html">Advanced Python Concepts</a><ul>
<li class="toctree-l3"><a class="reference internal" href="11AdvancedPython.html#Packing-and-unpacking-of-values">Packing and unpacking of values</a></li>
<li class="toctree-l3"><a class="reference internal" href="11AdvancedPython.html#Context-manager">Context manager</a><ul>
<li class="toctree-l4"><a class="reference internal" href="11AdvancedPython.html#Using-yield">Using <code class="docutils literal notranslate"><span class="pre">yield</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="11AdvancedPython.html#Using-a-class">Using a class</a></li>
<li class="toctree-l3"><a class="reference internal" href="11AdvancedPython.html#Decorators-and-factories">Decorators and factories</a><ul>
<li class="toctree-l4"><a class="reference internal" href="11AdvancedPython.html#Decorator">Decorator</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="11AdvancedPython.html#Exceptions">Exceptions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="11AdvancedPython.html#Custom-Exception">Custom Exception</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="11AdvancedPython.html#Catching-exceptions">Catching exceptions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="11AdvancedPython.html#pitfall-%22guaranteed-execution%22">pitfall “guaranteed execution”</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="11AdvancedPython.html#Exceptions-as-control-flow">Exceptions as control-flow</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="12AdvancedClasses.html">Advanced Classes</a><ul>
<li class="toctree-l3"><a class="reference internal" href="12AdvancedClasses.html#Dunder">Dunder</a></li>
<li class="toctree-l3"><a class="reference internal" href="12AdvancedClasses.html#len">len</a></li>
<li class="toctree-l3"><a class="reference internal" href="12AdvancedClasses.html#str">str</a></li>
<li class="toctree-l3"><a class="reference internal" href="12AdvancedClasses.html#Callable">Callable</a></li>
<li class="toctree-l3"><a class="reference internal" href="12AdvancedClasses.html#Indexing-(iterating)">Indexing (iterating)</a></li>
<li class="toctree-l3"><a class="reference internal" href="12AdvancedClasses.html#self">self</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="12AdvancedClasses.html#Danger-zone">Danger zone</a></li>
<li class="toctree-l2"><a class="reference internal" href="20DataAndPlotting.html">2: First look at data</a><ul>
<li class="toctree-l3"><a class="reference internal" href="20DataAndPlotting.html#Two-plotting-libraries?">Two plotting libraries?</a></li>
<li class="toctree-l3"><a class="reference internal" href="20DataAndPlotting.html#Recap:-Importing-modules">Recap: Importing modules</a><ul>
<li class="toctree-l4"><a class="reference internal" href="20DataAndPlotting.html#5.-The-toy-dataset">5. The toy dataset</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="20DataAndPlotting.html#Loading-data">Loading data</a><ul>
<li class="toctree-l4"><a class="reference internal" href="20DataAndPlotting.html#6.-Plotting-a-simple-histogram">6. Plotting a simple histogram</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="20DataAndPlotting.html#Adding-variables">Adding variables</a><ul>
<li class="toctree-l4"><a class="reference internal" href="20DataAndPlotting.html#Using-rectangular-cuts">Using rectangular cuts</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="20DataAndPlotting.html#Comparing-distributions">Comparing distributions</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="30Classification.html">3: Multivariate Analysis</a><ul>
<li class="toctree-l3"><a class="reference internal" href="30Classification.html#Using-a-classifier">Using a classifier</a><ul>
<li class="toctree-l4"><a class="reference internal" href="30Classification.html#TODO-Add-a-diagram-of-a-decision-tree-for-the-above-plot">TODO Add a diagram of a decision tree for the above plot</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="31ClassificationExtension.html">4: Extension on Classification</a><ul>
<li class="toctree-l3"><a class="reference internal" href="31ClassificationExtension.html#Alternative-implimentations">Alternative implimentations</a></li>
<li class="toctree-l3"><a class="reference internal" href="31ClassificationExtension.html#Feature-engineering">Feature engineering</a></li>
<li class="toctree-l3"><a class="reference internal" href="31ClassificationExtension.html#k-folding"><span class="math notranslate nohighlight">\(k\)</span>-folding</a></li>
<li class="toctree-l3"><a class="reference internal" href="31ClassificationExtension.html#Turn-this-into-a-scipt-using-argparse">Turn this into a scipt using argparse</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="32BoostingToUniformity.html">5: Boosting to Uniformity</a><ul>
<li class="toctree-l3"><a class="reference internal" href="32BoostingToUniformity.html#Loading-data">Loading data</a><ul>
<li class="toctree-l4"><a class="reference internal" href="32BoostingToUniformity.html#Distributions-in-the-Dalitz-features-for-signal-and-background">Distributions in the Dalitz features for signal and background</a></li>
<li class="toctree-l4"><a class="reference internal" href="32BoostingToUniformity.html#Preparation-of-train/test-datasets">Preparation of train/test datasets</a></li>
<li class="toctree-l4"><a class="reference internal" href="32BoostingToUniformity.html#Setting-up-classifiers,-training">Setting up classifiers, training</a></li>
<li class="toctree-l4"><a class="reference internal" href="32BoostingToUniformity.html#Let's-look-at-the-results-of-training">Let’s look at the results of training</a></li>
<li class="toctree-l4"><a class="reference internal" href="32BoostingToUniformity.html#ROC-curves-after-training">ROC curves after training</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Model tuning setup</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Cross-validation">Cross-validation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#k-folding-&amp;-early-stopping"><span class="math notranslate nohighlight">\(k\)</span>-folding &amp; early stopping</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Hyperameter-optimisation">Hyperameter optimisation</a></li>
<li class="toctree-l2"><a class="reference internal" href="40Histograms.html">6: Histograms</a><ul>
<li class="toctree-l3"><a class="reference internal" href="40Histograms.html#Axes">Axes</a><ul>
<li class="toctree-l4"><a class="reference internal" href="40Histograms.html#Regular">Regular</a></li>
<li class="toctree-l4"><a class="reference internal" href="40Histograms.html#Variable">Variable</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="40Histograms.html#Axis-Name">Axis Name</a><ul>
<li class="toctree-l4"><a class="reference internal" href="40Histograms.html#Compatibility-with-mplhep">Compatibility with mplhep</a></li>
<li class="toctree-l4"><a class="reference internal" href="40Histograms.html#Plotting-with-hist">Plotting with hist</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="40Histograms.html#Multiple-dimensions">Multiple dimensions</a></li>
<li class="toctree-l3"><a class="reference internal" href="40Histograms.html#Access-Bins">Access Bins</a></li>
<li class="toctree-l3"><a class="reference internal" href="40Histograms.html#Getting-Density">Getting Density</a></li>
<li class="toctree-l3"><a class="reference internal" href="40Histograms.html#Projecting-axes">Projecting axes</a></li>
<li class="toctree-l3"><a class="reference internal" href="40Histograms.html#Accessing-everything-relevant">Accessing everything relevant</a><ul>
<li class="toctree-l4"><a class="reference internal" href="40Histograms.html#Multi-dimensional">Multi dimensional</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="40Histograms.html#Arithmetics">Arithmetics</a></li>
<li class="toctree-l3"><a class="reference internal" href="40Histograms.html#Weights">Weights</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="45DemoReweighting.html">7: Demonstration of distribution reweighting</a><ul>
<li class="toctree-l3"><a class="reference internal" href="45DemoReweighting.html#Downloading-data">Downloading data</a></li>
<li class="toctree-l3"><a class="reference internal" href="45DemoReweighting.html#prepare-train-and-test-samples">prepare train and test samples</a><ul>
<li class="toctree-l4"><a class="reference internal" href="45DemoReweighting.html#Original-distributions">Original distributions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="45DemoReweighting.html#train-part-of-original-distribution">train part of original distribution</a></li>
<li class="toctree-l3"><a class="reference internal" href="45DemoReweighting.html#test-part-for-target-distribution">test part for target distribution</a></li>
<li class="toctree-l3"><a class="reference internal" href="45DemoReweighting.html#Bins-based-reweighting-in-n-dimensions">Bins-based reweighting in n dimensions</a></li>
<li class="toctree-l3"><a class="reference internal" href="45DemoReweighting.html#Gradient-Boosted-Reweighter">Gradient Boosted Reweighter</a><ul>
<li class="toctree-l4"><a class="reference internal" href="45DemoReweighting.html#Comparing-some-simple-expressions:">Comparing some simple expressions:</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="45DemoReweighting.html#GB-discrimination">GB-discrimination</a><ul>
<li class="toctree-l4"><a class="reference internal" href="45DemoReweighting.html#Great!">Great!</a></li>
<li class="toctree-l4"><a class="reference internal" href="45DemoReweighting.html#What-did-just-happen?">What did just happen?</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="45DemoReweighting.html#How-to-tune">How to tune</a></li>
<li class="toctree-l3"><a class="reference internal" href="45DemoReweighting.html#Folding-reweighter">Folding reweighter</a></li>
<li class="toctree-l3"><a class="reference internal" href="45DemoReweighting.html#GB-discrimination-for-reweighting-rule">GB discrimination for reweighting rule</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="50LikelihoodInference.html">8: Likelihood inference</a><ul>
<li class="toctree-l3"><a class="reference internal" href="50LikelihoodInference.html#Scope-of-this-tutorial">Scope of this tutorial</a></li>
<li class="toctree-l3"><a class="reference internal" href="50LikelihoodInference.html#Getting-started">Getting started</a></li>
<li class="toctree-l3"><a class="reference internal" href="50LikelihoodInference.html#Difference-of-the-two-spaces">Difference of the two spaces</a></li>
<li class="toctree-l3"><a class="reference internal" href="50LikelihoodInference.html#Plotting">Plotting</a></li>
<li class="toctree-l3"><a class="reference internal" href="50LikelihoodInference.html#Loss">Loss</a><ul>
<li class="toctree-l4"><a class="reference internal" href="50LikelihoodInference.html#Fixing-parameters">Fixing parameters</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="60sPlot.html">9: sPlot</a><ul>
<li class="toctree-l3"><a class="reference internal" href="60sPlot.html#Simple-sPlot-example">Simple sPlot example</a></li>
<li class="toctree-l3"><a class="reference internal" href="60sPlot.html#Observed-distributions">Observed distributions</a></li>
<li class="toctree-l3"><a class="reference internal" href="60sPlot.html#Applying-sWeights">Applying sWeights</a><ul>
<li class="toctree-l4"><a class="reference internal" href="60sPlot.html#Compare">Compare</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="60sPlot.html#More-complex-case">More complex case</a></li>
<li class="toctree-l3"><a class="reference internal" href="60sPlot.html#Splot">Splot</a></li>
<li class="toctree-l3"><a class="reference internal" href="60sPlot.html#Alternative:-Known-probabilities">Alternative: Known probabilities</a><ul>
<li class="toctree-l4"><a class="reference internal" href="60sPlot.html#Building-sPlot-over-mass">Building sPlot over mass</a></li>
<li class="toctree-l4"><a class="reference internal" href="60sPlot.html#Of-course-we-don't-have-labels-which-events-are-signal-and-which-are-background-beforehand">Of course we don’t have labels which events are signal and which are background beforehand</a></li>
<li class="toctree-l4"><a class="reference internal" href="60sPlot.html#We-have-no-information-about-real-labels">We have no information about real labels</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="60sPlot.html#Fitting-doesn't-give-us-information-about-real-labels">Fitting doesn’t give us information about real labels</a></li>
<li class="toctree-l3"><a class="reference internal" href="60sPlot.html#Appying-sPlot">Appying sPlot</a></li>
<li class="toctree-l3"><a class="reference internal" href="60sPlot.html#Using-sWeights-to-reconstruct-initial-distribution">Using sWeights to reconstruct initial distribution</a></li>
<li class="toctree-l3"><a class="reference internal" href="60sPlot.html#An-important-requirement-of-sPlot">An important requirement of sPlot</a></li>
<li class="toctree-l3"><a class="reference internal" href="60sPlot.html#Derivation-of-sWeights-(optional)">Derivation of sWeights (optional)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="60sPlot.html#Under-assumption-of-linearity:">Under assumption of linearity:</a></li>
<li class="toctree-l4"><a class="reference internal" href="60sPlot.html#Minimization-of-variation">Minimization of variation</a></li>
<li class="toctree-l4"><a class="reference internal" href="60sPlot.html#Uncorrelatedness">Uncorrelatedness</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="60sPlot.html#Conclusion">Conclusion</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="70ScikitHEPUniverse.html">10: Scikit-HEP</a><ul>
<li class="toctree-l3"><a class="reference internal" href="70ScikitHEPUniverse.html#formulate---converting-expressions">formulate - converting expressions</a></li>
<li class="toctree-l3"><a class="reference internal" href="70ScikitHEPUniverse.html#Particle">Particle</a></li>
<li class="toctree-l3"><a class="reference internal" href="70ScikitHEPUniverse.html#hepunits">hepunits</a></li>
<li class="toctree-l3"><a class="reference internal" href="70ScikitHEPUniverse.html#Vector">Vector</a><ul>
<li class="toctree-l4"><a class="reference internal" href="70ScikitHEPUniverse.html#Vector-properties">Vector properties</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../shell/README.html">Introducing the Shell</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../shell/README.html#background">Background</a></li>
<li class="toctree-l2"><a class="reference internal" href="../shell/README.html#the-command-line-interface">The Command-Line Interface</a></li>
<li class="toctree-l2"><a class="reference internal" href="../shell/README.html#the-shell">The Shell</a></li>
<li class="toctree-l2"><a class="reference internal" href="../shell/README.html#why-bother">Why bother?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../shell/README.html#nelle-s-pipeline-starting-point">Nelle’s Pipeline: Starting Point</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../shell/02-filedir.html">Navigating Files and Directories</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../shell/02-filedir.html#nelle-s-pipeline-organizing-files">Nelle’s Pipeline: Organizing Files</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../shell/03-create.html">Working With Files and Directories</a></li>
<li class="toctree-l3"><a class="reference internal" href="../shell/04-pipefilter.html">Pipes and Filters</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../shell/04-pipefilter.html#nelle-s-pipeline-checking-files">Nelle’s Pipeline: Checking Files</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../shell/05-loop.html">Loops</a></li>
<li class="toctree-l3"><a class="reference internal" href="../shell/06-script.html">Shell Scripts</a></li>
<li class="toctree-l3"><a class="reference internal" href="../shell/07-find.html">Finding Things</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../shell-extras/README.html">UNIX shell</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../shell-extras/screen.html">Using screen to keep things running</a></li>
<li class="toctree-l2"><a class="reference internal" href="../shell-extras/screen2.html">Advanced screen topics</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../shell-extras/screen2.html#finding-lost-screens">Finding lost screens</a></li>
<li class="toctree-l3"><a class="reference internal" href="../shell-extras/screen2.html#using-tabs-in-screen">Using tabs in screen</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../shell-extras/persistent-screen.html">Persistent screen or tmux session on lxplus</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../shell-extras/persistent-screen.html#setting-up-password-less-kerberos-token">Setting up password-less kerberos token</a></li>
<li class="toctree-l3"><a class="reference internal" href="../shell-extras/persistent-screen.html#making-use-of-the-keytab">Making use of the keytab</a></li>
<li class="toctree-l3"><a class="reference internal" href="../shell-extras/persistent-screen.html#using-k5reauth-to-automatically-refresh-your-kerberos-token">Using k5reauth to automatically refresh your kerberos token</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../shell-extras/shell2.html">More about the UNIX shell</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../shell-extras/shell2.html#types-of-shell">Types of shell</a></li>
<li class="toctree-l3"><a class="reference internal" href="../shell-extras/shell2.html#manual-pages">Manual pages</a></li>
<li class="toctree-l3"><a class="reference internal" href="../shell-extras/shell2.html#environment-variables">Environment variables</a></li>
<li class="toctree-l3"><a class="reference internal" href="../shell-extras/shell2.html#variables">Variables</a></li>
<li class="toctree-l3"><a class="reference internal" href="../shell-extras/shell2.html#differences-among-files">Differences among files</a></li>
<li class="toctree-l3"><a class="reference internal" href="../shell-extras/shell2.html#looping-over-files">Looping over files</a></li>
<li class="toctree-l3"><a class="reference internal" href="../shell-extras/shell2.html#conditionals">Conditionals</a></li>
<li class="toctree-l3"><a class="reference internal" href="../shell-extras/shell2.html#linking-commands">Linking commands</a></li>
<li class="toctree-l3"><a class="reference internal" href="../shell-extras/shell2.html#pipes-and-redirection">Pipes and redirection</a></li>
<li class="toctree-l3"><a class="reference internal" href="../shell-extras/shell2.html#bash-security">Bash security</a></li>
<li class="toctree-l3"><a class="reference internal" href="../shell-extras/shell2.html#complexity">Complexity</a></li>
<li class="toctree-l3"><a class="reference internal" href="../shell-extras/shell2.html#text-viewers">Text viewers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../shell-extras/shell2.html#text-editors">Text editors</a></li>
<li class="toctree-l3"><a class="reference internal" href="../shell-extras/shell2.html#disk-space">Disk space</a></li>
<li class="toctree-l3"><a class="reference internal" href="../shell-extras/shell2.html#over-the-wire-and-bandit-wargame">Over the Wire and Bandit wargame</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../snakemake/README.html">Analysis automation with Snakemake</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../snakemake/README.html#documentation-and-environments">Documentation and environments</a></li>
<li class="toctree-l2"><a class="reference internal" href="../snakemake/README.html#workflow-preservation">Workflow preservation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../snakemake/README.html#basic-tutorial">Basic Tutorial</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../snakemake/README.html#what-is-a-workflow">What is a workflow?</a></li>
<li class="toctree-l3"><a class="reference internal" href="../snakemake/README.html#why-use-a-workflow-management-system">Why use a workflow management system?</a></li>
<li class="toctree-l3"><a class="reference internal" href="../snakemake/README.html#introducing-snakemake">Introducing Snakemake</a></li>
<li class="toctree-l3"><a class="reference internal" href="../snakemake/README.html#re-running-rules">Re-running rules</a></li>
<li class="toctree-l3"><a class="reference internal" href="../snakemake/README.html#chaining-rules">Chaining rules</a></li>
<li class="toctree-l3"><a class="reference internal" href="../snakemake/README.html#the-limits-of-wildcards">The limits of wildcards</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../snakemake/README.html#advanced-tutorial">Advanced Tutorial</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../snakemake/README.html#running-scripts">Running scripts</a></li>
<li class="toctree-l3"><a class="reference internal" href="../snakemake/README.html#log-files">Log files</a></li>
<li class="toctree-l3"><a class="reference internal" href="../snakemake/README.html#config-files">Config files</a></li>
<li class="toctree-l3"><a class="reference internal" href="../snakemake/README.html#includes">Includes</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../git/README.html">Git</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../git/01-basics.html">Automated Version Control</a></li>
<li class="toctree-l2"><a class="reference internal" href="../git/02-setup.html">Setting Up Git</a></li>
<li class="toctree-l2"><a class="reference internal" href="../git/03-create.html">Creating a Repository</a></li>
<li class="toctree-l2"><a class="reference internal" href="../git/04-changes.html">Tracking Changes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../git/05-history.html">Exploring History</a></li>
<li class="toctree-l2"><a class="reference internal" href="../git/06-ignore.html">Ignoring Things</a></li>
<li class="toctree-l2"><a class="reference internal" href="../git/07-gitlab.html">Remotes in CERN GitLab</a></li>
<li class="toctree-l2"><a class="reference internal" href="../git/08-share.html">Sharing a repository with others</a></li>
<li class="toctree-l2"><a class="reference internal" href="../git/09-pullrequests.html">Collaborating with Pull Requests</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../git/09-pullrequests.html#what-is-a-pull-or-merge-request">What is a Pull (or Merge) Request</a></li>
<li class="toctree-l3"><a class="reference internal" href="../git/09-pullrequests.html#fork-the-original-project-repository">Fork the original project repository</a></li>
<li class="toctree-l3"><a class="reference internal" href="../git/09-pullrequests.html#clone-a-remote-project-and-its-fork">Clone a remote project and its fork</a></li>
<li class="toctree-l3"><a class="reference internal" href="../git/09-pullrequests.html#sync-your-local-repository-with-remote-changes">Sync your local repository with remote changes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../git/09-pullrequests.html#implement-your-new-feature">Implement your new feature</a></li>
<li class="toctree-l3"><a class="reference internal" href="../git/09-pullrequests.html#push-changes">Push changes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../git/09-pullrequests.html#create-a-pull-or-merge-request">Create a Pull (or Merge) Request</a></li>
<li class="toctree-l3"><a class="reference internal" href="../git/09-pullrequests.html#discussing-amending-retiring-a-merge-request">Discussing, amending, retiring a Merge Request</a></li>
<li class="toctree-l3"><a class="reference internal" href="../git/09-pullrequests.html#accepting-a-pull-request">Accepting a Pull Request</a></li>
<li class="toctree-l3"><a class="reference internal" href="../git/09-pullrequests.html#the-social-side-of-coding">The social side of coding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../git/09-pullrequests.html#automatic-testing">Automatic testing</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../git/10-conflict.html">Conflicts</a></li>
<li class="toctree-l2"><a class="reference internal" href="../git/11-ci.html">GitLab CI</a></li>
<li class="toctree-l2"><a class="reference internal" href="../git/12-open.html">Open Science</a></li>
<li class="toctree-l2"><a class="reference internal" href="../git/13-licensing.html">Licensing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../git/14-citation.html">Citation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../CONTRIBUTING.html">Contributing</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../CONTRIBUTING.html#contributor-agreement">Contributor Agreement</a></li>
<li class="toctree-l2"><a class="reference internal" href="../CONTRIBUTING.html#how-to-contribute">How to Contribute</a></li>
<li class="toctree-l2"><a class="reference internal" href="../CONTRIBUTING.html#what-to-contribute">What to Contribute</a></li>
<li class="toctree-l2"><a class="reference internal" href="../CONTRIBUTING.html#using-github">Using GitHub</a></li>
<li class="toctree-l2"><a class="reference internal" href="../CONTRIBUTING.html#other-resources">Other Resources</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../CONDUCT.html">Contributor Code of Conduct</a></li>
<li class="toctree-l1"><a class="reference internal" href="../LICENSE.html">Instructional Material</a></li>
<li class="toctree-l1"><a class="reference internal" href="../LICENSE.html#software">Software</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Analysis essentials</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="README.html">Advanced Python Tutorial</a></li>
      <li class="breadcrumb-item active">Model tuning setup</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/hsf-training/analysis-essentials/blob/master/advanced-python/33ModelTuning.ipynb" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="Model-tuning-setup">
<h1>Model tuning setup<a class="headerlink" href="#Model-tuning-setup" title="Link to this heading"></a></h1>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#%store -r training_data</span>
<span class="c1">#%store -r training_columns</span>
<span class="c1">#%store -r bkg_df</span>
<span class="c1">#%store -r mc_df</span>
<span class="c1">#%store -r data_df</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title</span>
<span class="c1">#!pip install uproot</span>
<span class="c1">#!pip install sklearn</span>

<span class="kn">import</span> <span class="nn">time</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">uproot</span>
<span class="kn">import</span> <span class="nn">xgboost</span> <span class="k">as</span> <span class="nn">xgb</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">AdaBoostClassifier</span><span class="p">,</span> <span class="n">GradientBoostingClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">auc</span><span class="p">,</span> <span class="n">roc_curve</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="p">(</span><span class="n">GridSearchCV</span><span class="p">,</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">cross_val_score</span><span class="p">,</span>
                                     <span class="n">cross_validate</span><span class="p">,</span> <span class="n">train_test_split</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">xgboost.sklearn</span> <span class="kn">import</span> <span class="n">XGBClassifier</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/tmp/ipykernel_4718/1411477585.py:8: DeprecationWarning:
Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),
(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)
but was not found to be installed on your system.
If this would cause problems for you,
please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466

  import pandas as pd
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Time and processing check for the lesson</span>
<span class="n">stt</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">stc</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">process_time</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_mass</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="n">counts</span><span class="p">,</span> <span class="n">bins</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Jpsi_M&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="nb">range</span><span class="o">=</span><span class="p">[</span><span class="mf">2.75</span><span class="p">,</span> <span class="mf">3.5</span><span class="p">],</span> <span class="n">histtype</span><span class="o">=</span><span class="s1">&#39;step&#39;</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="n">norm</span><span class="p">)</span>
    <span class="c1"># You can also use LaTeX in the axis label</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;$J/</span><span class="se">\\</span><span class="s1">psi$ mass [GeV]&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">bins</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">bins</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_comparision</span><span class="p">(</span><span class="n">var</span><span class="p">,</span> <span class="n">mc_df</span><span class="p">,</span> <span class="n">bkg_df</span><span class="p">):</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">bins</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">mc_df</span><span class="p">[</span><span class="n">var</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">histtype</span><span class="o">=</span><span class="s1">&#39;step&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;MC&#39;</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">bins</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">bkg_df</span><span class="p">[</span><span class="n">var</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="n">bins</span><span class="p">,</span> <span class="n">histtype</span><span class="o">=</span><span class="s1">&#39;step&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Background&#39;</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">var</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">bins</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">bins</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_roc</span><span class="p">(</span><span class="n">bdt</span><span class="p">,</span> <span class="n">training_data</span><span class="p">,</span> <span class="n">training_columns</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">y_score</span> <span class="o">=</span> <span class="n">bdt</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">training_data</span><span class="p">[</span><span class="n">training_columns</span><span class="p">])[:,</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">training_data</span><span class="p">[</span><span class="s1">&#39;catagory&#39;</span><span class="p">],</span> <span class="n">y_score</span><span class="p">)</span>
    <span class="n">area</span> <span class="o">=</span> <span class="n">auc</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;grey&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">label</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">label</span><span class="si">}</span><span class="s1"> (area = </span><span class="si">{</span><span class="n">area</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;ROC curve (area = </span><span class="si">{</span><span class="n">area</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;False Positive Rate&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;True Positive Rate&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;lower right&#39;</span><span class="p">)</span>
    <span class="c1"># We can make the plot look nicer by forcing the grid to be square</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="s1">&#39;equal&#39;</span><span class="p">,</span> <span class="n">adjustable</span><span class="o">=</span><span class="s1">&#39;box&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_significance</span><span class="p">(</span><span class="n">bdt</span><span class="p">,</span> <span class="n">training_data</span><span class="p">,</span> <span class="n">training_columns</span><span class="p">,</span> <span class="n">label</span><span class="p">):</span>
    <span class="n">y_score</span> <span class="o">=</span> <span class="n">bdt</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">training_data</span><span class="p">[</span><span class="n">training_columns</span><span class="p">])[:,</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">training_data</span><span class="p">[</span><span class="s1">&#39;catagory&#39;</span><span class="p">],</span> <span class="n">y_score</span><span class="p">)</span>

    <span class="n">n_sig</span> <span class="o">=</span> <span class="mi">1200</span>
    <span class="n">n_bkg</span> <span class="o">=</span> <span class="mi">23000</span>
    <span class="n">S</span> <span class="o">=</span> <span class="n">n_sig</span><span class="o">*</span><span class="n">tpr</span> <span class="o">+</span> <span class="p">(</span><span class="n">n_sig</span><span class="o">*</span><span class="n">tpr</span><span class="o">==</span><span class="mi">0</span><span class="p">)</span><span class="o">*</span><span class="mi">1</span>
    <span class="n">B</span> <span class="o">=</span> <span class="n">n_bkg</span><span class="o">*</span><span class="n">fpr</span> <span class="o">+</span> <span class="p">(</span><span class="n">n_bkg</span><span class="o">*</span><span class="n">tpr</span><span class="o">==</span><span class="mi">0</span><span class="p">)</span><span class="o">*</span><span class="mi">1</span>
    <span class="n">metric</span> <span class="o">=</span> <span class="n">S</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">S</span><span class="o">+</span><span class="n">B</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">thresholds</span><span class="p">,</span> <span class="n">metric</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;BDT cut value&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;$</span><span class="se">\\</span><span class="s1">frac</span><span class="si">{S}</span><span class="s1">{</span><span class="se">\\</span><span class="s1">sqrt{S+B}}$&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>

    <span class="n">optimum</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">metric</span><span class="p">)</span>
    <span class="n">optimal_cut</span> <span class="o">=</span> <span class="n">thresholds</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">metric</span><span class="p">)]</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="s2">&quot;:  S/sqrt(S+B) =&quot;</span><span class="p">,</span> <span class="n">optimum</span><span class="p">,</span> <span class="s2">&quot; at x =&quot;</span><span class="p">,</span> <span class="n">optimal_cut</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">optimal_cut</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">optimal_cut</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#max_entries = 1000 # try running with low stats for bug fixing your changes quickly</span>
<span class="n">data_df</span> <span class="o">=</span> <span class="n">uproot</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s1">&#39;https://cern.ch/starterkit/data/advanced-python-2018/real_data.root&#39;</span><span class="p">,</span>
                    <span class="n">httpsource</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;chunkbytes&#39;</span><span class="p">:</span> <span class="mi">1024</span><span class="o">*</span><span class="mi">1024</span><span class="p">,</span> <span class="s1">&#39;limitbytes&#39;</span><span class="p">:</span> <span class="mi">33554432</span><span class="p">,</span> <span class="s1">&#39;parallel&#39;</span><span class="p">:</span> <span class="mi">64</span><span class="p">}</span>
                    <span class="p">)[</span><span class="s1">&#39;DecayTree&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">arrays</span><span class="p">(</span><span class="n">library</span><span class="o">=</span><span class="s1">&#39;pd&#39;</span><span class="p">)</span><span class="c1">#,entry_stop=max_entries)</span>
<span class="n">mc_df</span> <span class="o">=</span> <span class="n">uproot</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s1">&#39;https://cern.ch/starterkit/data/advanced-python-2018/simulated_data.root&#39;</span><span class="p">,</span>
                    <span class="n">httpsource</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;chunkbytes&#39;</span><span class="p">:</span> <span class="mi">1024</span><span class="o">*</span><span class="mi">1024</span><span class="p">,</span> <span class="s1">&#39;limitbytes&#39;</span><span class="p">:</span> <span class="mi">33554432</span><span class="p">,</span> <span class="s1">&#39;parallel&#39;</span><span class="p">:</span> <span class="mi">64</span><span class="p">}</span>
                    <span class="p">)[</span><span class="s1">&#39;DecayTree&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">arrays</span><span class="p">(</span><span class="n">library</span><span class="o">=</span><span class="s1">&#39;pd&#39;</span><span class="p">)</span><span class="c1">#,entry_stop=max_entries)</span>
<span class="n">bkg_df</span> <span class="o">=</span> <span class="n">data_df</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="s1">&#39;~(3.0 &lt; Jpsi_M &lt; 3.2)&#39;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">df</span> <span class="ow">in</span> <span class="p">[</span><span class="n">mc_df</span><span class="p">,</span> <span class="n">data_df</span><span class="p">,</span> <span class="n">bkg_df</span><span class="p">]:</span>
    <span class="n">df</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="s1">&#39;Jpsi_eta = arctanh(Jpsi_PZ/Jpsi_P)&#39;</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">df</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="s1">&#39;mup_P = sqrt(mum_PX**2 + mum_PY**2 + mum_PZ**2)&#39;</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">df</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="s1">&#39;mum_P = sqrt(mum_PX**2 + mum_PY**2 + mum_PZ**2)&#39;</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">bkg_df</span><span class="p">[</span><span class="s1">&#39;catagory&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># Use 0 for background</span>
<span class="n">mc_df</span><span class="p">[</span><span class="s1">&#39;catagory&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>  <span class="c1"># Use 1 for signal</span>
<span class="n">training_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">bkg_df</span><span class="p">,</span> <span class="n">mc_df</span><span class="p">],</span> <span class="n">copy</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">for</span> <span class="n">df</span> <span class="ow">in</span> <span class="p">[</span><span class="n">mc_df</span><span class="p">,</span> <span class="n">bkg_df</span><span class="p">,</span> <span class="n">data_df</span><span class="p">,</span> <span class="n">training_data</span><span class="p">]:</span>
    <span class="n">df</span><span class="p">[</span><span class="s1">&#39;IPdiff&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;mum_PT&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;mup_PT&#39;</span><span class="p">])</span>

<span class="n">training_columns</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s1">&#39;Jpsi_PT&#39;</span><span class="p">,</span>
    <span class="s1">&#39;mup_PT&#39;</span><span class="p">,</span> <span class="s1">&#39;mup_eta&#39;</span><span class="p">,</span> <span class="s1">&#39;mup_ProbNNmu&#39;</span><span class="p">,</span> <span class="s1">&#39;mup_IP&#39;</span><span class="p">,</span>
    <span class="s1">&#39;mum_PT&#39;</span><span class="p">,</span> <span class="s1">&#39;mum_eta&#39;</span><span class="p">,</span> <span class="s1">&#39;mum_ProbNNmu&#39;</span><span class="p">,</span> <span class="s1">&#39;mum_IP&#39;</span><span class="p">,</span>
<span class="p">]</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/tmp/ipykernel_4718/2007768199.py:11: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df.eval(&#39;Jpsi_eta = arctanh(Jpsi_PZ/Jpsi_P)&#39;, inplace=True)
/tmp/ipykernel_4718/2007768199.py:12: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df.eval(&#39;mup_P = sqrt(mum_PX**2 + mum_PY**2 + mum_PZ**2)&#39;, inplace=True)
/tmp/ipykernel_4718/2007768199.py:13: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df.eval(&#39;mum_P = sqrt(mum_PX**2 + mum_PY**2 + mum_PZ**2)&#39;, inplace=True)
/tmp/ipykernel_4718/2007768199.py:15: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  bkg_df[&#39;catagory&#39;] = 0  # Use 0 for background
/tmp/ipykernel_4718/2007768199.py:19: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df[&#39;IPdiff&#39;] = np.abs(df[&#39;mum_PT&#39;] - df[&#39;mup_PT&#39;])
</pre></div></div>
</div>
<p>Previously we trained an XGBClassifier with the default settings, with learning rate = 0.3 and maximum iterations = 100. This cut off to the training process may be limiting the performance of our model. We can monitor the performance of our model as a function of training iteration and stop the training when the gradient approximates zero.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X1</span><span class="p">,</span> <span class="n">y1</span> <span class="o">=</span> <span class="n">training_data</span><span class="p">[</span><span class="n">training_columns</span><span class="p">],</span> <span class="n">training_data</span><span class="p">[</span><span class="s1">&#39;catagory&#39;</span><span class="p">]</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">y1</span><span class="p">)</span>
<span class="c1"># default train_size = 0.25, this can be varied to suit your data</span>

<span class="n">LR</span> <span class="o">=</span> <span class="mf">0.3</span> <span class="c1"># the coefficient of step size decay, eta, has alias &#39;learning_rate&#39; with default 0.3</span>

<span class="n">stime</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">bdt</span> <span class="o">=</span> <span class="n">XGBClassifier</span><span class="p">(</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">LR</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">123</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">bdt</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">training_data</span><span class="p">[</span><span class="n">training_columns</span><span class="p">],</span> <span class="n">training_data</span><span class="p">[</span><span class="s1">&#39;catagory&#39;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;XGBoost --- </span><span class="si">%s</span><span class="s2"> seconds ---&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">stime</span><span class="p">))</span>

<span class="k">for</span> <span class="n">df</span> <span class="ow">in</span> <span class="p">[</span><span class="n">mc_df</span><span class="p">,</span> <span class="n">bkg_df</span><span class="p">,</span> <span class="n">data_df</span><span class="p">,</span> <span class="n">training_data</span><span class="p">]:</span>
    <span class="n">df</span><span class="p">[</span><span class="s1">&#39;XGB&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">bdt</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">training_columns</span><span class="p">])[:,</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
XGBoost --- 0.8556647300720215 seconds ---
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/tmp/ipykernel_4718/3009250180.py:13: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df[&#39;XGB&#39;] = bdt.predict_proba(df[training_columns])[:,1]
</pre></div></div>
</div>
</section>
<section id="Cross-validation">
<h1>Cross-validation<a class="headerlink" href="#Cross-validation" title="Link to this heading"></a></h1>
<p>Splitting the data into randomised subsets for training allows you to monitor your model’s performance on the fly using the statistically independant remainder of your sample - this is called cross-validation (CV). We can see below that at the 100th iteration the metrics still show a trend of improvement.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">training_monitor</span><span class="p">(</span><span class="n">alg</span><span class="p">):</span>

  <span class="c1"># A model trained with eval_set and eval_metric will return evals_result</span>
  <span class="n">results</span> <span class="o">=</span> <span class="n">alg</span><span class="o">.</span><span class="n">evals_result</span><span class="p">()</span>
  <span class="n">epochs</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="s1">&#39;validation_0&#39;</span><span class="p">][</span><span class="s1">&#39;logloss&#39;</span><span class="p">])</span>
  <span class="n">x_axis</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">epochs</span><span class="p">)</span>

  <span class="c1"># Plotting logLoss as a function of training iteration</span>
  <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_axis</span><span class="p">,</span> <span class="n">results</span><span class="p">[</span><span class="s1">&#39;validation_0&#39;</span><span class="p">][</span><span class="s1">&#39;logloss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Train&#39;</span><span class="p">)</span> <span class="c1"># for each eval_set</span>
  <span class="k">if</span> <span class="n">results</span><span class="p">[</span><span class="s1">&#39;validation_1&#39;</span><span class="p">]:</span> <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_axis</span><span class="p">,</span> <span class="n">results</span><span class="p">[</span><span class="s1">&#39;validation_1&#39;</span><span class="p">][</span><span class="s1">&#39;logloss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Test&#39;</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;LogLoss&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;LogLoss&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

  <span class="c1"># Plotting classification error as a function of training iteration</span>
  <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_axis</span><span class="p">,</span> <span class="n">results</span><span class="p">[</span><span class="s1">&#39;validation_0&#39;</span><span class="p">][</span><span class="s1">&#39;error&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Train&#39;</span><span class="p">)</span>  <span class="c1"># for each eval_set</span>
  <span class="k">if</span> <span class="n">results</span><span class="p">[</span><span class="s1">&#39;validation_1&#39;</span><span class="p">]:</span> <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_axis</span><span class="p">,</span> <span class="n">results</span><span class="p">[</span><span class="s1">&#39;validation_1&#39;</span><span class="p">][</span><span class="s1">&#39;error&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Test&#39;</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Error&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Error&#39;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<p>This involves training on less data but allows us to monitor progress to check if the model is becoming over-specific to our training sample. The minimisation of loss and classification error are common metrics for model assessment. As shown below, the cost to performance is negligible. If the test sample gradient were to invert this would be considered overtraining and is why monitoring performance without CV can be a time costly pitfall.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Defining a model with multi-threading set to maximum</span>
<span class="n">bdt_cv</span> <span class="o">=</span> <span class="n">XGBClassifier</span><span class="p">(</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">LR</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">123</span><span class="p">,</span> <span class="n">n_threads</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Model fitting with CV and printing out processing time</span>
<span class="n">stime</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">bdt_cv</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">eval_metric</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;logloss&quot;</span><span class="p">,</span><span class="s2">&quot;error&quot;</span><span class="p">],</span>
           <span class="n">eval_set</span><span class="o">=</span><span class="p">[(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)],</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">XGBoost cross-validation --- </span><span class="si">%s</span><span class="s2"> seconds ---&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">stime</span><span class="p">))</span>

<span class="c1"># Writing model predictions out for data</span>
<span class="n">training_monitor</span><span class="p">(</span><span class="n">bdt_cv</span><span class="p">)</span>
<span class="k">for</span> <span class="n">df</span> <span class="ow">in</span> <span class="p">[</span><span class="n">mc_df</span><span class="p">,</span> <span class="n">bkg_df</span><span class="p">,</span> <span class="n">data_df</span><span class="p">,</span> <span class="n">training_data</span><span class="p">]:</span>
    <span class="n">df</span><span class="p">[</span><span class="s1">&#39;XGBcv&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">bdt_cv</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">training_columns</span><span class="p">])[:,</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/usr/share/miniconda/envs/analysis-essentials/lib/python3.11/site-packages/xgboost/sklearn.py:889: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.
  warnings.warn(
/usr/share/miniconda/envs/analysis-essentials/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [00:50:00] WARNING: /workspace/src/learner.cc:742:
Parameters: { &#34;n_threads&#34; } are not used.

  warnings.warn(smsg, UserWarning)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

XGBoost cross-validation --- 2.0221338272094727 seconds ---
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/advanced-python_33ModelTuning_14_2.png" src="../_images/advanced-python_33ModelTuning_14_2.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/advanced-python_33ModelTuning_14_3.png" src="../_images/advanced-python_33ModelTuning_14_3.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/tmp/ipykernel_4718/3553768138.py:13: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df[&#39;XGBcv&#39;] = bdt_cv.predict_proba(df[training_columns])[:,1]
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Drawing plot of model respone for signal and background classes</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plot_comparision</span><span class="p">(</span><span class="s1">&#39;XGB&#39;</span><span class="p">,</span> <span class="n">mc_df</span><span class="p">,</span> <span class="n">bkg_df</span><span class="p">)</span>
<span class="n">plot_comparision</span><span class="p">(</span><span class="s1">&#39;XGBcv&#39;</span><span class="p">,</span> <span class="n">mc_df</span><span class="p">,</span> <span class="n">bkg_df</span><span class="p">)</span>

<span class="c1"># Drawing the signal efficiency vs background rejection curve (ROC)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plot_roc</span><span class="p">(</span><span class="n">bdt</span><span class="p">,</span> <span class="n">training_data</span><span class="p">,</span> <span class="n">training_columns</span><span class="p">)</span>
<span class="n">plot_roc</span><span class="p">(</span><span class="n">bdt_cv</span><span class="p">,</span> <span class="n">training_data</span><span class="p">,</span> <span class="n">training_columns</span><span class="p">)</span>

<span class="c1"># Drawing signal significance comparison as a function of minimum cut on model response</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">bdt_cut</span> <span class="o">=</span> <span class="n">plot_significance</span><span class="p">(</span><span class="n">bdt</span><span class="p">,</span> <span class="n">training_data</span><span class="p">,</span> <span class="n">training_columns</span><span class="p">,</span> <span class="s2">&quot;bdt&quot;</span><span class="p">)</span>
<span class="n">bdt_cv_cut</span> <span class="o">=</span> <span class="n">plot_significance</span><span class="p">(</span><span class="n">bdt_cv</span><span class="p">,</span> <span class="n">training_data</span><span class="p">,</span> <span class="n">training_columns</span><span class="p">,</span> <span class="s2">&quot;bdt_cv&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
bdt :  S/sqrt(S+B) = 15.405805978293522  at x = 0.80857503
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
bdt_cv :  S/sqrt(S+B) = 15.284216832108756  at x = 0.82674176
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/advanced-python_33ModelTuning_15_2.png" src="../_images/advanced-python_33ModelTuning_15_2.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/advanced-python_33ModelTuning_15_3.png" src="../_images/advanced-python_33ModelTuning_15_3.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/advanced-python_33ModelTuning_15_4.png" src="../_images/advanced-python_33ModelTuning_15_4.png" />
</div>
</div>
</section>
<section id="k-folding-&amp;-early-stopping">
<h1><span class="math notranslate nohighlight">\(k\)</span>-folding &amp; early stopping<a class="headerlink" href="#k-folding-&-early-stopping" title="Link to this heading"></a></h1>
<p>Performing CV on each of a number, k, of ways to split your data gives you k models to choose from. Some choose to average the performance across the models from each fold as any instability might imply the model will not be reliable. The results below seem stable; each fold provides a consistant performance across multiple metrics, so we’ll just choose the best one.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Defining the folds with a seed to test consistently</span>
<span class="n">splits</span> <span class="o">=</span> <span class="mi">4</span> <span class="c1"># to match 0.25 value of test_train_split default though this may not be optimal</span>
<span class="n">kf</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="n">splits</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">)</span>

<span class="c1"># Printing processing time of the kfold cross-validation</span>
<span class="n">stime</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">kf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X1</span><span class="p">):</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span> <span class="o">=</span> <span class="n">X1</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train</span><span class="p">],</span> <span class="n">X1</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">test</span><span class="p">]</span>
    <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">y1</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train</span><span class="p">],</span> <span class="n">y1</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">test</span><span class="p">]</span>
    <span class="n">bdt</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">XGBoost k-folding --- </span><span class="si">%s</span><span class="s2"> seconds ---&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">stime</span><span class="p">))</span>

<span class="c1"># Calculating scores of each fold using variety of CV-metrics</span>
<span class="n">cv_acc</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">bdt</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">splits</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;accuracy&quot;</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">cv_los</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">bdt</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">splits</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;neg_log_loss&quot;</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">cv_auc</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">bdt</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">splits</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;roc_auc&quot;</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Printing results and indicating best fold</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;accuracy: &quot;</span><span class="p">,</span><span class="n">cv_acc</span><span class="p">,</span> <span class="s2">&quot; -&gt;  best fold =&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">cv_acc</span><span class="p">)</span> <span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-logloss: &quot;</span><span class="p">,</span><span class="n">cv_los</span><span class="p">,</span> <span class="s2">&quot; -&gt;  best fold =&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">cv_los</span><span class="p">)</span> <span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;roc_auc:  &quot;</span><span class="p">,</span><span class="n">cv_auc</span><span class="p">,</span> <span class="s2">&quot; -&gt;  best fold =&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">cv_auc</span><span class="p">)</span> <span class="p">)</span>
<span class="n">bestfold</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">cv_acc</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

XGBoost k-folding --- 2.713792562484741 seconds ---
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
accuracy:  [0.78412488 0.77760064 0.78477481 0.78856118]  -&gt;  best fold = 3
-logloss:  [-0.42945196 -0.43137575 -0.42765048 -0.42374993]  -&gt;  best fold = 3
roc_auc:   [0.87520356 0.87239133 0.8768386  0.87975731]  -&gt;  best fold = 3
</pre></div></div>
</div>
<p>Early stopping defines a maximum number of rounds the cross-validation metric (we’ll use ‘error’=1-accuracy) is allowed to not improve before training is terminated. As is standard, we will be reverting back to a ‘previous best’ model based on test sample score, this helps avoid overtraining. Early stopping prevents us training too many of extra models thus saving time. Set the limit too small though and your training might be cut off prematurely.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">modelfit</span><span class="p">(</span><span class="n">alg</span><span class="p">,</span> <span class="n">metric</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">predictors</span><span class="p">,</span> <span class="n">kfold</span><span class="p">,</span> <span class="n">fbest</span><span class="p">,</span> <span class="n">early_stop</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>

    <span class="c1"># Loading data split inputs providing best fold result</span>
    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">test</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">kf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">params</span><span class="p">)):</span>
      <span class="k">if</span> <span class="p">(</span><span class="n">k</span><span class="o">==</span><span class="n">fbest</span><span class="p">):</span>
        <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span> <span class="o">=</span> <span class="n">params</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train</span><span class="p">],</span> <span class="n">params</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">test</span><span class="p">]</span>
        <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">label</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train</span><span class="p">],</span> <span class="n">label</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">test</span><span class="p">]</span>

    <span class="c1"># Defining data in terms of training variables and class label</span>
    <span class="n">xgb_param</span> <span class="o">=</span> <span class="n">alg</span><span class="o">.</span><span class="n">get_xgb_params</span><span class="p">()</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">DMatrix</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">,</span> <span class="n">feature_names</span><span class="o">=</span><span class="n">predictors</span><span class="p">,</span> <span class="n">nthread</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Runs timed CV on our model using early stopping based on our metric</span>
    <span class="n">stime</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">cvresult</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">cv</span><span class="p">(</span><span class="n">xgb_param</span><span class="p">,</span>
                      <span class="n">data</span><span class="p">,</span>
                      <span class="n">num_boost_round</span><span class="o">=</span><span class="n">alg</span><span class="o">.</span><span class="n">get_params</span><span class="p">()[</span><span class="s1">&#39;n_estimators&#39;</span><span class="p">],</span>
                      <span class="c1">#nfold=cv_folds, # to use in build folding</span>
                      <span class="n">folds</span><span class="o">=</span><span class="n">kfold</span><span class="p">,</span> <span class="c1"># use -&gt; ignores nfold</span>
                      <span class="n">metrics</span><span class="o">=</span><span class="n">metric</span><span class="p">,</span>
                      <span class="n">early_stopping_rounds</span><span class="o">=</span><span class="n">early_stop</span><span class="p">)</span>
    <span class="n">alg</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="n">cvresult</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">XGBoost early-stop folding --- </span><span class="si">%s</span><span class="s2"> seconds ---&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">stime</span><span class="p">))</span>

    <span class="c1"># Fitting the algorithm on the data with CV evaluation early stopping</span>
    <span class="n">stime</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">alg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">eval_metric</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;logloss&quot;</span><span class="p">,</span><span class="s2">&quot;error&quot;</span><span class="p">],</span>
            <span class="n">eval_set</span><span class="o">=</span><span class="p">[(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)],</span>
            <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">early_stopping_rounds</span><span class="o">=</span><span class="n">early_stop</span><span class="p">)</span>
    <span class="n">training_monitor</span><span class="p">(</span><span class="n">alg</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;XGBoost early-stop limit --- </span><span class="si">%s</span><span class="s2"> seconds ---&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">stime</span><span class="p">))</span>

    <span class="c1"># Predicting training set:</span>
    <span class="n">train_predictions</span> <span class="o">=</span> <span class="n">alg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
    <span class="n">test_predictions</span> <span class="o">=</span> <span class="n">alg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

    <span class="c1"># Printing model report:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Model Report : best iteration &quot;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">cvresult</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Train Accuracy : &quot;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">train_predictions</span><span class="p">)))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test Accuracy : &quot;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">test_predictions</span><span class="p">)))</span>
    <span class="k">return</span> <span class="n">cvresult</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
<p>This function incorporates the k-folding CV and early stopping, saving not only the optimal model but also the index of its training iteration. This means, in our subsequent steps, we can apply an upper limit on training for models based on the convergence of the default hyperparameters, saving us some time.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Defining model with high maximum estimators for use with early stopping</span>
<span class="n">bdt_es</span> <span class="o">=</span> <span class="n">XGBClassifier</span><span class="p">(</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">LR</span><span class="p">,</span>   <span class="n">n_estimators</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
                       <span class="c1"># Default values of other hyperparamters</span>
                       <span class="c1">#max_depth=6,          min_child_weight=1,</span>
                       <span class="c1">#gamma=0,              subsample=0.8,</span>
                       <span class="c1">#colsample_bytree=0.8, scale_pos_weight=1,</span>
                       <span class="c1">#objective=&#39;binary:logistic&#39;, # default for binary classification</span>
                       <span class="c1">#objective=&#39;mutli:softprob&#39;, num_class=3, # for multiclassifiers</span>
                       <span class="n">seed</span><span class="o">=</span><span class="mi">123</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Timing the CV using early stopping</span>
<span class="n">stime</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">estimators</span> <span class="o">=</span> <span class="n">modelfit</span><span class="p">(</span><span class="n">bdt_es</span><span class="p">,</span> <span class="s2">&quot;error&quot;</span><span class="p">,</span> <span class="n">X1</span><span class="p">,</span> <span class="n">y1</span><span class="p">,</span> <span class="n">training_columns</span><span class="p">,</span> <span class="n">kf</span><span class="p">,</span> <span class="n">bestfold</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">modelfit(bdt_es) --- </span><span class="si">%s</span><span class="s2"> seconds ---&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">stime</span><span class="p">))</span>

<span class="c1"># Saving model predictions</span>
<span class="k">for</span> <span class="n">df</span> <span class="ow">in</span> <span class="p">[</span><span class="n">mc_df</span><span class="p">,</span> <span class="n">bkg_df</span><span class="p">,</span> <span class="n">data_df</span><span class="p">,</span> <span class="n">training_data</span><span class="p">]:</span>
    <span class="n">df</span><span class="p">[</span><span class="s1">&#39;XGBes&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">bdt_es</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">training_columns</span><span class="p">])[:,</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

XGBoost early-stop folding --- 16.265354871749878 seconds ---
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/usr/share/miniconda/envs/analysis-essentials/lib/python3.11/site-packages/xgboost/sklearn.py:889: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.
  warnings.warn(
/usr/share/miniconda/envs/analysis-essentials/lib/python3.11/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.
  warnings.warn(
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/advanced-python_33ModelTuning_21_2.png" src="../_images/advanced-python_33ModelTuning_21_2.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/advanced-python_33ModelTuning_21_3.png" src="../_images/advanced-python_33ModelTuning_21_3.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
XGBoost early-stop limit --- 6.2194907665252686 seconds ---
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Model Report : best iteration 320
Train Accuracy : 0.878406430077885
Test Accuracy : 0.8180580234817411

modelfit(bdt_es) --- 23.111666679382324 seconds ---
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/tmp/ipykernel_4718/41647419.py:18: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df[&#39;XGBes&#39;] = bdt_es.predict_proba(df[training_columns])[:,1]
</pre></div></div>
</div>
<p>This provides us with an improved model as well as a benchmark to test against in both performance and training efficiency. When training using new combinations of hyperparameters, the maximum number of estimators from our model report will cut off any new models improving more slowly than our default, while, for more efficient models, the early stopping will kick in.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Drawing plot to compare model response for signal and background classes</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plot_comparision</span><span class="p">(</span><span class="s1">&#39;XGBcv&#39;</span><span class="p">,</span> <span class="n">mc_df</span><span class="p">,</span> <span class="n">bkg_df</span><span class="p">)</span>
<span class="n">plot_comparision</span><span class="p">(</span><span class="s1">&#39;XGBes&#39;</span><span class="p">,</span> <span class="n">mc_df</span><span class="p">,</span> <span class="n">bkg_df</span><span class="p">)</span>

<span class="c1"># Drawing comaprison of the signal efficiency vs background rejection curve (ROC)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plot_roc</span><span class="p">(</span><span class="n">bdt_cv</span><span class="p">,</span> <span class="n">training_data</span><span class="p">,</span> <span class="n">training_columns</span><span class="p">)</span>
<span class="n">plot_roc</span><span class="p">(</span><span class="n">bdt_es</span><span class="p">,</span> <span class="n">training_data</span><span class="p">,</span> <span class="n">training_columns</span><span class="p">)</span>

<span class="c1"># Drawing signal significance comparison as a function of minimum cut on model response</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">bdt_cut_cv</span> <span class="o">=</span> <span class="n">plot_significance</span><span class="p">(</span><span class="n">bdt_cv</span><span class="p">,</span> <span class="n">training_data</span><span class="p">,</span> <span class="n">training_columns</span><span class="p">,</span> <span class="s2">&quot;bdt_cv&quot;</span><span class="p">)</span>
<span class="n">bdt_cut_es</span> <span class="o">=</span> <span class="n">plot_significance</span><span class="p">(</span><span class="n">bdt_es</span><span class="p">,</span> <span class="n">training_data</span><span class="p">,</span> <span class="n">training_columns</span><span class="p">,</span> <span class="s2">&quot;bdt_es&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
bdt_cv :  S/sqrt(S+B) = 15.284216832108756  at x = 0.82674176
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
bdt_es :  S/sqrt(S+B) = 18.05205070820643  at x = 0.7961289
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/advanced-python_33ModelTuning_23_2.png" src="../_images/advanced-python_33ModelTuning_23_2.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/advanced-python_33ModelTuning_23_3.png" src="../_images/advanced-python_33ModelTuning_23_3.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/advanced-python_33ModelTuning_23_4.png" src="../_images/advanced-python_33ModelTuning_23_4.png" />
</div>
</div>
</section>
<section id="Hyperameter-optimisation">
<h1>Hyperameter optimisation<a class="headerlink" href="#Hyperameter-optimisation" title="Link to this heading"></a></h1>
<p>Below we provide a “grid” of hyperparameters, defining the structure of the trees and constraints on the learning, but there are many more values to choose from and a larger parameter space to be explored. These optimsations are very problem specific and their impact will have to be weighed against the computing resources and timeframe you have at your disposal. For the sake of expedient demonstration we are comparing the default parameters to only one predetermined variation in 2 parameters.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define a function that performs a gridscan of HPs</span>


<span class="k">def</span> <span class="nf">hpgridscan</span><span class="p">(</span><span class="n">alg</span><span class="p">,</span> <span class="n">metric</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">kfold</span><span class="p">,</span> <span class="n">fbest</span><span class="p">,</span> <span class="n">early_stop</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>

  <span class="c1"># Load data fold with best performance</span>
  <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">test</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">kf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">params</span><span class="p">)):</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">k</span><span class="o">==</span><span class="n">fbest</span><span class="p">):</span>
      <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span> <span class="o">=</span> <span class="n">params</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train</span><span class="p">],</span> <span class="n">params</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">test</span><span class="p">]</span>
      <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">label</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train</span><span class="p">],</span> <span class="n">label</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">test</span><span class="p">]</span>

  <span class="c1"># Define a dictionary of numpy arrays for our HPs</span>
  <span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
      <span class="s1">&#39;max_depth&#39;</span><span class="p">:</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">7</span><span class="p">]),</span>
      <span class="s1">&#39;min_child_weight&#39;</span><span class="p">:</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">3</span><span class="p">]),</span>
      <span class="c1">#&#39;max_depth&#39;:np.arange(        5,   9,   1   ),</span>
      <span class="c1">#&#39;min_child_weight&#39;:np.arange( 1,   5,   1   ),</span>
      <span class="c1">##&#39;gamma&#39;:np.arange(            0.0, 1.0, 0.1 ),</span>
      <span class="c1">##&#39;colsample_bytree&#39;:np.arange( 0.4, 1.0, 0.1 ),</span>
      <span class="c1">##&#39;subsample&#39;:np.arange(        0.4, 1.0, 0.1 ),</span>
      <span class="c1">##&#39;scale_pos_weight&#39;:np.arange( 0.4, 1.6, 0.1 )</span>
      <span class="p">}</span>

  <span class="c1"># Perform timed grid scan with established n_estimator cutoff and early stopping</span>
  <span class="n">stime</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
  <span class="n">gs</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">alg</span><span class="p">,</span>
                    <span class="n">param_grid</span><span class="o">=</span><span class="n">params</span><span class="p">,</span>
                    <span class="n">scoring</span><span class="o">=</span><span class="n">metric</span><span class="p">,</span>
                    <span class="c1">#iid=False,</span>
                    <span class="n">cv</span><span class="o">=</span><span class="n">kf</span><span class="p">,</span>
                    <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
  <span class="n">gs</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">eval_metric</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;logloss&quot;</span><span class="p">,</span><span class="s2">&quot;error&quot;</span><span class="p">],</span>
         <span class="n">eval_set</span><span class="o">=</span><span class="p">[(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)],</span>
         <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">early_stopping_rounds</span><span class="o">=</span><span class="n">early_stop</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;XGBoost grid-scan --- </span><span class="si">%s</span><span class="s2"> seconds ---&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">stime</span><span class="p">))</span>

  <span class="c1"># Return suggested parameters, performance and best model</span>
  <span class="n">training_monitor</span><span class="p">(</span><span class="n">gs</span><span class="o">.</span><span class="n">best_estimator_</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Suggestion:&quot;</span><span class="p">,</span> <span class="n">gs</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy:&quot;</span> <span class="p">,</span><span class="n">gs</span><span class="o">.</span><span class="n">best_score_</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">gs</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Running with estimators maximum for shortened training</span>
<span class="n">bdt_st</span> <span class="o">=</span> <span class="n">XGBClassifier</span><span class="p">(</span> <span class="n">learning_rate</span> <span class="o">=</span> <span class="n">LR</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="n">estimators</span><span class="p">,</span>
                        <span class="n">seed</span><span class="o">=</span><span class="mi">123</span><span class="p">,</span>           <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Running timed hyperparameter gridscan</span>
<span class="n">stime</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">gs</span> <span class="o">=</span> <span class="n">hpgridscan</span><span class="p">(</span><span class="n">bdt_st</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">,</span> <span class="n">X1</span><span class="p">,</span> <span class="n">y1</span><span class="p">,</span> <span class="n">kf</span><span class="p">,</span> <span class="n">bestfold</span><span class="p">)</span>
<span class="n">bdt_gs</span> <span class="o">=</span> <span class="n">gs</span><span class="o">.</span><span class="n">best_estimator_</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">hpgridscan(bdt_st) --- </span><span class="si">%s</span><span class="s2"> seconds ---&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">stime</span><span class="p">))</span>

<span class="c1"># Get model predictions</span>
<span class="k">for</span> <span class="n">df</span> <span class="ow">in</span> <span class="p">[</span><span class="n">mc_df</span><span class="p">,</span> <span class="n">bkg_df</span><span class="p">,</span> <span class="n">data_df</span><span class="p">,</span> <span class="n">training_data</span><span class="p">]:</span>
    <span class="n">df</span><span class="p">[</span><span class="s1">&#39;XGBgs&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">bdt_gs</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">training_columns</span><span class="p">])[:,</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/usr/share/miniconda/envs/analysis-essentials/lib/python3.11/site-packages/xgboost/sklearn.py:889: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.
  warnings.warn(
/usr/share/miniconda/envs/analysis-essentials/lib/python3.11/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.
  warnings.warn(
/usr/share/miniconda/envs/analysis-essentials/lib/python3.11/site-packages/xgboost/sklearn.py:889: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.
  warnings.warn(
/usr/share/miniconda/envs/analysis-essentials/lib/python3.11/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.
  warnings.warn(
/usr/share/miniconda/envs/analysis-essentials/lib/python3.11/site-packages/xgboost/sklearn.py:889: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.
  warnings.warn(
/usr/share/miniconda/envs/analysis-essentials/lib/python3.11/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.
  warnings.warn(
/usr/share/miniconda/envs/analysis-essentials/lib/python3.11/site-packages/xgboost/sklearn.py:889: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.
  warnings.warn(
/usr/share/miniconda/envs/analysis-essentials/lib/python3.11/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.
  warnings.warn(
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/usr/share/miniconda/envs/analysis-essentials/lib/python3.11/site-packages/xgboost/sklearn.py:889: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.
  warnings.warn(
/usr/share/miniconda/envs/analysis-essentials/lib/python3.11/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.
  warnings.warn(
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
XGBoost grid-scan --- 18.899073839187622 seconds ---
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/advanced-python_33ModelTuning_26_3.png" src="../_images/advanced-python_33ModelTuning_26_3.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/advanced-python_33ModelTuning_26_4.png" src="../_images/advanced-python_33ModelTuning_26_4.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Suggestion: {&#39;max_depth&#39;: 7, &#39;min_child_weight&#39;: 3}
Accuracy: 0.8091291887649159

hpgridscan(bdt_st) --- 19.127185344696045 seconds ---
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/tmp/ipykernel_4718/1018627576.py:13: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df[&#39;XGBgs&#39;] = bdt_gs.predict_proba(df[training_columns])[:,1]
</pre></div></div>
</div>
<p>Even this naive grid scan, using the same fold as before for fair comparison, can provide significant improvements as demonstrated above. These may be pushed further by including more hyperparameters for a trade off with processing time. However, even with parrallisation these tasks can take hours or longer and might only provide improvement of O(&gt;1%).</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## We could define a model using optimal hyperparameters from our grid scan</span>
<span class="c1">#bdt_opt = XGBClassifier( learning_rate = LR, n_estimators=1000,</span>
<span class="c1">#                         max_depth=gs.best_params_[&#39;max_depth&#39;],</span>
<span class="c1">#                         min_child_weight=gs.best_params_[&#39;min_child_weight&#39;],</span>
<span class="c1">#                         seed=123, n_jobs=-1 )</span>

<span class="c1">## Run with CV early stopping</span>
<span class="c1">#stime = time.time()</span>
<span class="c1">#estimators = modelfit(bdt_opt, &#39;error&#39;, X1, y1, training_columns, kf, bestfold)</span>
<span class="c1">#print(&quot;\nmodelfit(bdt_opt) --- %s seconds ---&quot; % (time.time() - stime))</span>

<span class="c1">## Get model predictions</span>
<span class="c1">#for df in [mc_df, bkg_df, data_df, training_data]:</span>
<span class="c1">#    df[&#39;XGBopt&#39;] = bdt_opt.predict_proba(df[training_columns])[:,1]</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Comapring model response from the end of last session to the end of this one</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plot_comparision</span><span class="p">(</span><span class="s1">&#39;XGB&#39;</span><span class="p">,</span> <span class="n">mc_df</span><span class="p">,</span> <span class="n">bkg_df</span><span class="p">)</span>
<span class="n">plot_comparision</span><span class="p">(</span><span class="s1">&#39;XGBgs&#39;</span><span class="p">,</span> <span class="n">mc_df</span><span class="p">,</span> <span class="n">bkg_df</span><span class="p">)</span>

<span class="c1"># Comparing model performance for each level of tuning</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plot_roc</span><span class="p">(</span><span class="n">bdt</span><span class="p">,</span> <span class="n">training_data</span><span class="p">,</span> <span class="n">training_columns</span><span class="p">)</span>
<span class="n">plot_roc</span><span class="p">(</span><span class="n">bdt_cv</span><span class="p">,</span> <span class="n">training_data</span><span class="p">,</span> <span class="n">training_columns</span><span class="p">)</span>
<span class="n">plot_roc</span><span class="p">(</span><span class="n">bdt_es</span><span class="p">,</span> <span class="n">training_data</span><span class="p">,</span> <span class="n">training_columns</span><span class="p">)</span>
<span class="n">plot_roc</span><span class="p">(</span><span class="n">bdt_gs</span><span class="p">,</span> <span class="n">training_data</span><span class="p">,</span> <span class="n">training_columns</span><span class="p">)</span>
<span class="c1">#plot_roc(bdt_opt, training_data, training_columns)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/advanced-python_33ModelTuning_29_0.png" src="../_images/advanced-python_33ModelTuning_29_0.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/advanced-python_33ModelTuning_29_1.png" src="../_images/advanced-python_33ModelTuning_29_1.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Comparing the impact on projected performance at each stage of the tutorial</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">bdt_cut</span> <span class="o">=</span> <span class="n">plot_significance</span><span class="p">(</span><span class="n">bdt</span><span class="p">,</span> <span class="n">training_data</span><span class="p">,</span> <span class="n">training_columns</span><span class="p">,</span> <span class="s2">&quot;bdt&quot;</span><span class="p">)</span>
<span class="n">bdt_cv_cut</span> <span class="o">=</span> <span class="n">plot_significance</span><span class="p">(</span><span class="n">bdt_cv</span><span class="p">,</span> <span class="n">training_data</span><span class="p">,</span> <span class="n">training_columns</span><span class="p">,</span> <span class="s2">&quot;bdt_cv&quot;</span><span class="p">)</span>
<span class="n">bdt_es_cut</span> <span class="o">=</span> <span class="n">plot_significance</span><span class="p">(</span><span class="n">bdt_es</span><span class="p">,</span> <span class="n">training_data</span><span class="p">,</span> <span class="n">training_columns</span><span class="p">,</span> <span class="s2">&quot;bdt_es&quot;</span><span class="p">)</span>
<span class="n">bdt_gs_cut</span> <span class="o">=</span> <span class="n">plot_significance</span><span class="p">(</span><span class="n">bdt_gs</span><span class="p">,</span> <span class="n">training_data</span><span class="p">,</span> <span class="n">training_columns</span><span class="p">,</span> <span class="s2">&quot;bdt_gs&quot;</span><span class="p">)</span>
<span class="c1">#bdt_opt_cut = plot_significance(bdt_opt, training_data, training_columns, &quot;bdt_opt&quot;)</span>

<span class="c1"># Comparing best cuts impact on mass for original and tuned model</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">data_bdt_cut</span> <span class="o">=</span> <span class="n">data_df</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="s1">&#39;XGB &gt; </span><span class="si">%f</span><span class="s1">&#39;</span> <span class="o">%</span><span class="k">bdt_cut</span> )
<span class="n">plot_mass</span><span class="p">(</span><span class="n">data_bdt_cut</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;XGB default&#39;</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">data_gs_cut</span> <span class="o">=</span> <span class="n">data_df</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="s1">&#39;XGBgs &gt; </span><span class="si">%f</span><span class="s1">&#39;</span> <span class="o">%</span><span class="k">bdt_gs_cut</span> )
<span class="n">plot_mass</span><span class="p">(</span><span class="n">data_gs_cut</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;XGB tuned&#39;</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
bdt :  S/sqrt(S+B) = 15.225756452547515  at x = 0.8237634
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
bdt_cv :  S/sqrt(S+B) = 15.284216832108756  at x = 0.82674176
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
bdt_es :  S/sqrt(S+B) = 18.05205070820643  at x = 0.7961289
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
bdt_gs :  S/sqrt(S+B) = 17.817070520310462  at x = 0.8272739
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;matplotlib.legend.Legend at 0x7f6c17de7910&gt;
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/advanced-python_33ModelTuning_30_5.png" src="../_images/advanced-python_33ModelTuning_30_5.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/advanced-python_33ModelTuning_30_6.png" src="../_images/advanced-python_33ModelTuning_30_6.png" />
</div>
</div>
<p>Comparing our data sample’s mass plot having applied the cut optimised for <span class="math notranslate nohighlight">\(\sigma=\frac{S}{\sqrt{S+B}}\)</span> from each BDT output, we can see how the improved model reduces relative background. However, while we define our signal training sample from MC you’ll remember we defined our background training sample from the data !(3.0 &lt; JPsi_M &lt; 3.2).</p>
<p>We can see shoulders at the edges of the regions where we define our background training sample in our data’s mass spectrum now. Our training and validation samples include a subset of our data sample so there’s potential that our model is learning the difference between MC and data and exploiting that or demonstrating overtraining on the ‘previously seen’ data (remember we could see our train and test samples beginning to diverge in our validation metrics with more iterations).</p>
<p>Below you can see replotting the normalised mass distribution from just the data not included in training demonstrates no significant improvement. This is not ideal and might be addressed by choosing the setup of our training more carefully. For example, we could train using background from same-sign muon MC across the full mass range (a common practice in LHC experiments) or, using other libraries such as UGBoost to introduce a punishment to the training for introducing a depedance of
efficiency on mass.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[22]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sig_df</span> <span class="o">=</span> <span class="n">data_df</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="s1">&#39;(3.0 &lt; Jpsi_M &lt; 3.2)&#39;</span><span class="p">)</span>
<span class="n">sig_bdt_cut</span> <span class="o">=</span> <span class="n">sig_df</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="s1">&#39;XGB &gt; </span><span class="si">%f</span><span class="s1">&#39;</span> <span class="o">%</span><span class="k">bdt_cut</span> )
<span class="n">plot_mass</span><span class="p">(</span><span class="n">sig_bdt_cut</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;XGB default&#39;</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">sig_gs_cut</span> <span class="o">=</span> <span class="n">sig_df</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="s1">&#39;XGBgs &gt; </span><span class="si">%f</span><span class="s1">&#39;</span> <span class="o">%</span><span class="k">bdt_gs_cut</span> )
<span class="n">plot_mass</span><span class="p">(</span><span class="n">sig_gs_cut</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;XGB tuned&#39;</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[22]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;matplotlib.legend.Legend at 0x7f6c17d51e10&gt;
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/advanced-python_33ModelTuning_32_1.png" src="../_images/advanced-python_33ModelTuning_32_1.png" />
</div>
</div>
<p>You can also choose a higher learning rate to perform course scans of your space and decrease it again to retrain your final model. If you can afford to, it might be best to include learning rate itself as a parameter in your grid. With some libraries you can specify your choice of kernel. Both these choices will impact your optimal maximum number of iterations, so setting it sufficiently high and using early stopping might be a good strategy.</p>
<p>For less exhaustive and non-discritised methods try smart combinations of the following to perform adaptive scans or build your own: * sklearn.model_selection.RandomizedSearchCV * sklearn.model_selection.GridSearchCV</p>
<p>Moving to higher dimentional optimisation problems may require more sophisticated solutions: * skopt.BayesSearchCV * hyperopt.tpe</p>
<p>Full stats plots saved here: bit.ly/LHCb_XGB_Tuning Run with full stats by removing entrystop at max_events in cell 8.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Final lesson time and processing time check</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Notebook real time --- </span><span class="si">%s</span><span class="s2"> seconds ---&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">stt</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Notebook CPU time --- </span><span class="si">%s</span><span class="s2"> seconds ---&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">process_time</span><span class="p">()</span> <span class="o">-</span> <span class="n">stc</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Notebook real time --- 401.37995314598083 seconds ---
Notebook CPU time --- 182.2430899 seconds ---
</pre></div></div>
</div>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="32BoostingToUniformity.html" class="btn btn-neutral float-left" title="5: Boosting to Uniformity" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="40Histograms.html" class="btn btn-neutral float-right" title="6: Histograms" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright HSF CC BY 4.0 (https://creativecommons.org/licenses/by/4.0/legalcode) - Originally based on Software Carpentry (https://github.com/swcarpentry/) © 2016–2017 Software Carpentry Foundation.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
    Hello world


</body>
</html>